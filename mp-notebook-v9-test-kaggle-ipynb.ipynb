{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[{"file_id":"14sXDYyegbMQjRaEottMtnEr-SDILHZrW","timestamp":1771328894458}],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14862945,"sourceType":"datasetVersion","datasetId":9507658}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\nMAIN SETTINGS\n</div>","metadata":{"id":"8u27b0sPG4SA"}},{"cell_type":"code","source":"###SETTINGS###\n\nimport os\nimport re\nimport time\nimport subprocess\nimport shutil\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom getpass import getpass\nfrom urllib.parse import urlencode\n\n# Platform detection\nON_KAGGLE = os.path.exists('/kaggle')\nON_COLAB = 'COLAB_RELEASE_TAG' in os.environ or os.path.exists('/content')\nON_VAST = any(k in os.environ for k in (\"VAST_CONTAINERLABEL\", \"VAST_TCP_PORT_22\", \"CONTAINER_ID\")) or os.path.exists('/workspace')\n\n\nMAX_PARALLEL_DOWNLOADS = max(1, int(os.environ.get(\"MAX_PARALLEL_DOWNLOADS\", \"3\")))\nMIN_VALID_FILE_BYTES = int(os.environ.get(\"MIN_VALID_FILE_BYTES\", \"1000000\"))\n\nif shutil.which(\"aria2c\") is None:\n    print(\"aria2c not found → installing...\")\n    try:\n        subprocess.run([\"apt\", \"update\", \"-qq\"], check=True, capture_output=True)\n        result = subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", \"aria2\"], capture_output=True, text=True)\n        if result.returncode == 0:\n            print(\"aria2c installed successfully\")\n        else:\n            print(\"Install failed (code {}):\".format(result.returncode))\n            print(\"stderr:\", result.stderr.strip())\n    except subprocess.CalledProcessError as e:\n        print(f\"apt error (code {e.returncode}): {e.stderr}\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\nelse:\n    print(\"aria2c already available\")\n\n# Determining the working directory\npossible_bases = [\n    \"/workspace\",       # Vast.ai / RunPod\n    \"/kaggle/working\",  # Kaggle\n    \"/content\",         # Google Colab\n]\n\nBASE_DIR = None\nfor path in possible_bases:\n    if os.path.isdir(path):\n        BASE_DIR = path\n        break\n\nif BASE_DIR is None:\n    BASE_DIR = os.getcwd()\n    print(\"WARNING: Known directory not found:\", BASE_DIR)\n\nprint(\"Working directory:\", BASE_DIR)\n\n# Configuration\nFORGE_DIR        = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\")\nMODELS_DIR       = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Stable-diffusion\")\nLORA_DIR         = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Lora\")\nCONTROLNET_DIR   = os.path.join(FORGE_DIR, \"extensions\", \"sd-webui-controlnet\")\nCONTROLNET_MODELS_DIR = os.path.join(CONTROLNET_DIR, \"models\")\nEXTENSIONS_DIR   = os.path.join(FORGE_DIR, \"extensions\")\nOUTPUTS_DIR      = os.path.join(FORGE_DIR, \"outputs\")\nVOLUME_DIR       = os.path.join(BASE_DIR, \"volume\")\nGEN_DIR          = os.path.join(BASE_DIR, \"gen\")\n\nfor d in [MODELS_DIR, LORA_DIR, CONTROLNET_DIR, CONTROLNET_MODELS_DIR, EXTENSIONS_DIR, OUTPUTS_DIR, VOLUME_DIR, GEN_DIR]:\n    os.makedirs(d, exist_ok=True)\n\n# Dependencies used by generation cell\nfor pkg in [\"openpyxl\", \"requests\"]:\n    try:\n        __import__(pkg)\n    except Exception:\n        print(f\"Installing missing dependency: {pkg}\")\n        subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-q\", pkg], check=False)\n\n\ndef get_secret(name: str):\n    \"\"\"Get secret from env/Kaggle/Colab only.\"\"\"\n    value = os.environ.get(name)\n    if value:\n        return value.strip(), \"env\"\n\n    # Kaggle secrets\n    if ON_KAGGLE:\n        try:\n            from kaggle_secrets import UserSecretsClient\n            value = UserSecretsClient().get_secret(name)\n            if value:\n                return value.strip(), \"kaggle_secrets\"\n        except Exception:\n            pass\n\n    # Colab secrets panel: from google.colab import userdata\n    if ON_COLAB:\n        try:\n            from google.colab import userdata\n            value = userdata.get(name)\n            if value:\n                return value.strip(), \"colab_userdata\"\n        except Exception:\n            pass\n\n    return None, None\n\n\nCIVITAI_TOKEN, CIVITAI_SRC = get_secret(\"CIVITAI_TOKEN\")\nHF_TOKEN, HF_SRC = get_secret(\"HF_TOKEN\")\n\nif not CIVITAI_TOKEN:\n    manual_civitai = getpass(\"Enter CIVITAI_TOKEN (leave blank to skip): \").strip()\n    if manual_civitai:\n        CIVITAI_TOKEN, CIVITAI_SRC = manual_civitai, \"manual_input\"\n\nif not HF_TOKEN:\n    manual_hf = getpass(\"Enter HF_TOKEN (leave blank to skip): \").strip()\n    if manual_hf:\n        HF_TOKEN, HF_SRC = manual_hf, \"manual_input\"\n\nTOKENS = {}\nif CIVITAI_TOKEN:\n    TOKENS[\"CIVITAI\"] = CIVITAI_TOKEN\nif HF_TOKEN:\n    TOKENS[\"HF_TOKEN\"] = HF_TOKEN\n\nprint(\"Token sources:\")\nprint(f\"  CIVITAI_TOKEN: {CIVITAI_SRC or 'not found'}\")\nprint(f\"  HF_TOKEN: {HF_SRC or 'not found'}\")\nif ON_VAST:\n    print(\"Vast.ai tip: add CIVITAI_TOKEN/HF_TOKEN in template env vars, restart container, then rerun this cell.\")\n\nif not CIVITAI_TOKEN:\n    print(\"CivitAI token not found\")\nif not HF_TOKEN:\n    print(\"HF token not found\")\nif not TOKENS:\n    raise RuntimeError(\"No tokens were provided. Set secrets or enter at least one token (CivitAI or HF).\")\n\n\ndef _prepare_download_url(url, token):\n    \"\"\"CivitAI download works more reliably with token as query param.\"\"\"\n    if token and \"civitai.com/api/download/models\" in url and \"token=\" not in url:\n        sep = \"&\" if \"?\" in url else \"?\"\n        return f\"{url}{sep}{urlencode({'token': token})}\"\n    return url\n\n\ndef _looks_valid_file(path, min_bytes=MIN_VALID_FILE_BYTES):\n    return os.path.exists(path) and os.path.getsize(path) > min_bytes\n\n\ndef _human_mb(num_bytes):\n    return f\"{num_bytes / (1024 * 1024):.1f} MB\"\n\n\ndef _estimate_expected_mb(label):\n    # Examples: \"151 MB\", \"6,46 GB\"\n    match = re.search(r\"(\\d+[\\.,]?\\d*)\\s*(MB|GB)\", label, re.IGNORECASE)\n    if not match:\n        return None\n    value = float(match.group(1).replace(',', '.'))\n    unit = match.group(2).upper()\n    return value * (1024 if unit == \"GB\" else 1)\n\n\ndef _size_sanity_warning(path, expected_mb, tolerance=0.7):\n    if expected_mb is None or not os.path.exists(path):\n        return\n    actual_mb = os.path.getsize(path) / (1024 * 1024)\n    if actual_mb < expected_mb * tolerance:\n        print(f\"  WARNING: file size looks low ({actual_mb:.1f} MB vs expected ~{expected_mb:.1f} MB)\")\n\n\ndef _has_min_free_disk(path, required_mb, reserve_mb=1024):\n    if required_mb is None:\n        return True\n    usage = shutil.disk_usage(path)\n    free_mb = usage.free / (1024 * 1024)\n    return free_mb >= (required_mb + reserve_mb)\n\n\ndef _download_one(job, target_dir):\n    label, url, filename, token_name = job\n    token = TOKENS.get(token_name)\n    output_path = os.path.join(target_dir, filename)\n\n    expected_mb = _estimate_expected_mb(label)\n\n    if _looks_valid_file(output_path):\n        size = os.path.getsize(output_path)\n        print(f\"[SKIP] {label}: already exists ({_human_mb(size)})\")\n        _size_sanity_warning(output_path, expected_mb)\n        return (label, True, \"exists\")\n\n    if expected_mb is not None and not _has_min_free_disk(target_dir, expected_mb):\n        return (label, False, \"insufficient_disk\")\n\n    tmp_path = output_path + \".part\"\n    if os.path.exists(tmp_path):\n        os.remove(tmp_path)\n\n    final_url = _prepare_download_url(url, token if token_name == \"CIVITAI\" else None)\n\n    cmd = [\n        \"aria2c\",\n        \"--allow-overwrite=true\",\n        \"--auto-file-renaming=false\",\n        \"--continue=true\",\n        \"--max-connection-per-server=16\",\n        \"--split=16\",\n        \"--min-split-size=1M\",\n        \"--console-log-level=warn\",\n        \"--summary-interval=1\",\n        \"--check-certificate=false\",\n        \"--out\", os.path.basename(tmp_path),\n        \"--dir\", target_dir,\n        final_url,\n    ]\n\n    if token_name == \"HF_TOKEN\" and token:\n        cmd.insert(-1, f\"--header=Authorization: Bearer {token}\")\n\n    print(f\"[DOWNLOADING] {label}\")\n    result = subprocess.run(cmd, text=True, capture_output=True)\n    if result.returncode != 0:\n        stderr = (result.stderr or \"\").strip()\n        stdout = (result.stdout or \"\").strip()\n        msg = stderr or stdout or f\"aria2c exited {result.returncode}\"\n        if os.path.exists(tmp_path):\n            os.remove(tmp_path)\n        return (label, False, msg)\n\n    if not _looks_valid_file(tmp_path):\n        size = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0\n        if os.path.exists(tmp_path):\n            os.remove(tmp_path)\n        return (label, False, f\"downloaded file too small ({_human_mb(size)})\")\n\n    os.replace(tmp_path, output_path)\n    _size_sanity_warning(output_path, expected_mb)\n    return (label, True, _human_mb(os.path.getsize(output_path)))\n\n\ndef run_download_list(download_list, target_dir, title):\n    print(f\"\\n=== {title} ===\")\n    os.makedirs(target_dir, exist_ok=True)\n\n    if not download_list:\n        print(\"No items.\")\n        return\n\n    workers = min(MAX_PARALLEL_DOWNLOADS, len(download_list))\n    print(f\"Parallel downloads: {workers}\")\n\n    ok = 0\n    fail = 0\n\n    with ThreadPoolExecutor(max_workers=workers) as ex:\n        futures = [ex.submit(_download_one, job, target_dir) for job in download_list]\n        for fut in as_completed(futures):\n            label, success, info = fut.result()\n            if success:\n                ok += 1\n                print(f\"[OK]   {label} -> {info}\")\n            else:\n                fail += 1\n                print(f\"[FAIL] {label} -> {info}\")\n\n    print(f\"Done: OK={ok}, FAIL={fail}\")\n    if fail > 0:\n        raise RuntimeError(f\"Some downloads failed in {title}: {fail} item(s)\")\n\n\n","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"kTzG8SwHG4SC","executionInfo":{"status":"ok","timestamp":1771328411100,"user_tz":-120,"elapsed":18125,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"f393f94c-ad89-4ada-cf09-46ff7662971f","execution":{"iopub.status.busy":"2026-02-17T14:21:33.267028Z","iopub.execute_input":"2026-02-17T14:21:33.267583Z","iopub.status.idle":"2026-02-17T14:21:49.978018Z","shell.execute_reply.started":"2026-02-17T14:21:33.267555Z","shell.execute_reply":"2026-02-17T14:21:49.977296Z"}},"outputs":[{"name":"stdout","text":"aria2c not found → installing...\naria2c installed successfully\nWorking directory: /kaggle/working\nToken sources:\n  CIVITAI_TOKEN: kaggle_secrets\n  HF_TOKEN: kaggle_secrets\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"### OPTIONAL: KAGGLE/COLAB FORGE BOOTSTRAP ###\n\nimport os\nimport shutil\nimport subprocess\n\nif not (ON_KAGGLE or ON_COLAB):\n    print(\"Optional cell: предназначена только для Kaggle/Colab. Текущая платформа пропущена.\")\nelse:\n    required_packages = [\"git\", \"python3-venv\", \"python3-pip\"]\n    print(\"Checking/installing platform dependencies...\")\n    subprocess.run([\"apt\", \"update\", \"-qq\"], check=False)\n    subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", *required_packages], check=False)\n\n    launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n    git_head = os.path.join(FORGE_DIR, \".git\", \"HEAD\")\n    forge_ready = os.path.isfile(launch_script) and os.path.isfile(git_head)\n\n    if forge_ready:\n        print(\"WebUI Forge already exists and looks valid, skipping clone.\")\n    else:\n        if os.path.isdir(FORGE_DIR):\n            print(\"FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\")\n            shutil.rmtree(FORGE_DIR)\n\n        print(\"Cloning WebUI Forge...\")\n        subprocess.run([\n            \"git\", \"clone\", \"https://github.com/lllyasviel/stable-diffusion-webui-forge\", FORGE_DIR\n        ], check=True)\n\n        if not os.path.isfile(os.path.join(FORGE_DIR, \"webui.sh\")):\n            raise FileNotFoundError(\"Clone completed but webui.sh not found. Check repository state.\")\n\n    print(\"Optional bootstrap finished.\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wM3J4QA4G4SK","executionInfo":{"status":"ok","timestamp":1771328433337,"user_tz":-120,"elapsed":22233,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"6be9f00e-054b-4d09-a4c0-9c4486b602bd","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T14:21:49.979466Z","iopub.execute_input":"2026-02-17T14:21:49.979932Z","iopub.status.idle":"2026-02-17T14:22:16.766490Z","shell.execute_reply.started":"2026-02-17T14:21:49.979906Z","shell.execute_reply":"2026-02-17T14:22:16.765857Z"}},"outputs":[{"name":"stdout","text":"Checking/installing platform dependencies...\n","output_type":"stream"},{"name":"stderr","text":"\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n\n","output_type":"stream"},{"name":"stdout","text":"171 packages can be upgraded. Run 'apt list --upgradable' to see them.\ngit is already the newest version (1:2.34.1-1ubuntu1.15).\nThe following additional packages will be installed:\n  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n  python3-pip-whl python3-pkg-resources python3-setuptools\n  python3-setuptools-whl python3-wheel python3.10 python3.10-dev\n  python3.10-minimal python3.10-venv\nSuggested packages:\n  python-setuptools-doc python3.10-doc binfmt-support\nThe following NEW packages will be installed:\n  python3-pip python3-pip-whl python3-setuptools python3-setuptools-whl\n  python3-venv python3-wheel python3.10-venv\nThe following packages will be upgraded:\n  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n  python3-pkg-resources python3.10 python3.10-dev python3.10-minimal\n8 upgraded, 7 newly installed, 0 to remove and 163 not upgraded.\nNeed to get 17.2 MB of archives.\nAfter this operation, 12.4 MB of additional disk space will be used.\n(Reading database ... 129147 files and directories currently installed.)\nPreparing to unpack .../00-python3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-dev (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../01-libpython3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../02-libpython3.10_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../03-python3.10_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../04-libpython3.10-stdlib_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../05-python3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-minimal (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../06-libpython3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../07-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\nSelecting previously unselected package python3-setuptools.\nPreparing to unpack .../08-python3-setuptools_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-setuptools (68.1.2-2~jammy3) ...\nSelecting previously unselected package python3-wheel.\nPreparing to unpack .../09-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\nUnpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\nSelecting previously unselected package python3-pip.\nPreparing to unpack .../10-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\nUnpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\nSelecting previously unselected package python3-pip-whl.\nPreparing to unpack .../11-python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\nUnpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\nSelecting previously unselected package python3-setuptools-whl.\nPreparing to unpack .../12-python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\nSelecting previously unselected package python3.10-venv.\nPreparing to unpack .../13-python3.10-venv_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-venv (3.10.12-1~22.04.14) ...\nSelecting previously unselected package python3-venv.\nPreparing to unpack .../14-python3-venv_3.10.6-1~22.04.1_amd64.deb ...\nUnpacking python3-venv (3.10.6-1~22.04.1) ...\nSetting up python3-pkg-resources (68.1.2-2~jammy3) ...\nSetting up python3-setuptools-whl (68.1.2-2~jammy3) ...\nSetting up python3-setuptools (68.1.2-2~jammy3) ...\nSetting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\nSetting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\nSetting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\nSetting up python3.10-minimal (3.10.12-1~22.04.14) ...\nSetting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) ...\nSetting up libpython3.10:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3.10 (3.10.12-1~22.04.14) ...\nSetting up libpython3.10-dev:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3.10-dev (3.10.12-1~22.04.14) ...\nSetting up python3.10-venv (3.10.12-1~22.04.14) ...\nSetting up python3-venv (3.10.6-1~22.04.1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\nFORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\nCloning WebUI Forge...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge'...\n","output_type":"stream"},{"name":"stdout","text":"Optional bootstrap finished.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"### CONTROLNET INSTALL OPTIONS ###\n\n# Option A (default): force clean reinstall\n# Option B: set CONTROLNET_INSTALL_MODE = \"update\" for git pull in existing repo\n# Option C: set CONTROLNET_INSTALL_MODE = \"skip\" to keep current state\n\nCONTROLNET_REPO_URL = \"https://github.com/Mikubill/sd-webui-controlnet\"\nCONTROLNET_INSTALL_MODE = os.environ.get(\"CONTROLNET_INSTALL_MODE\", \"reinstall\").strip().lower()\n\nif CONTROLNET_INSTALL_MODE not in {\"reinstall\", \"update\", \"skip\"}:\n    raise ValueError(\"CONTROLNET_INSTALL_MODE must be one of: reinstall, update, skip\")\n\nprint(f\"ControlNet extension path: {CONTROLNET_DIR}\")\nprint(f\"Install mode: {CONTROLNET_INSTALL_MODE}\")\n\nif CONTROLNET_INSTALL_MODE == \"skip\":\n    print(\"ControlNet install skipped\")\nelse:\n    if os.path.isdir(CONTROLNET_DIR) and CONTROLNET_INSTALL_MODE == \"reinstall\":\n        print(\"Removing existing ControlNet directory...\")\n        shutil.rmtree(CONTROLNET_DIR)\n\n    if not os.path.isdir(CONTROLNET_DIR):\n        print(\"Cloning ControlNet repository...\")\n        subprocess.run([\"git\", \"clone\", CONTROLNET_REPO_URL, CONTROLNET_DIR], check=True)\n    else:\n        print(\"Updating ControlNet repository...\")\n        subprocess.run([\"git\", \"-C\", CONTROLNET_DIR, \"pull\", \"--ff-only\"], check=True)\n\nos.makedirs(CONTROLNET_MODELS_DIR, exist_ok=True)\nprint(\"ControlNet repository is ready\")\nprint(f\"ControlNet models directory: {CONTROLNET_MODELS_DIR}\")\n\n#ControlNET models download\n\ncontrolnet_models_to_download = [\n    (\"t2i-adapter_xl_openpose 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_openpose.safetensors\", \"t2i-adapter_xl_openpose.safetensors\", \"HF_TOKEN\"),\n    (\"t2i-adapter_xl_canny 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_canny.safetensors\", \"t2i-adapter_xl_canny.safetensors\", \"HF_TOKEN\"),\n    (\"t2i-adapter_xl_sketch 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_sketch.safetensors\", \"t2i-adapter_xl_sketch.safetensors\", \"HF_TOKEN\"),\n    (\"t2i-adapter_diffusers_xl_depth_midas 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"HF_TOKEN\"),\n    (\"t2i-adapter_diffusers_xl_depth_zoe 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"HF_TOKEN\"),\n    (\"t2i-adapter_diffusers_xl_lineart 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_lineart.safetensors\", \"t2i-adapter_diffusers_xl_lineart.safetensors\", \"HF_TOKEN\"),\n]\n\nrun_download_list(controlnet_models_to_download, CONTROLNET_MODELS_DIR, \"ControlNet\")\n\n#Checkpoints download\n\nmodels_to_download = [\n    (\"WAI ILL V16.0 6,46 GB\", \"https://civitai.com/api/download/models/2514310?type=Model&format=SafeTensor&size=pruned&fp=fp16\", \"wai_v160.safetensors\", \"CIVITAI\"),\n]\n\nrun_download_list(models_to_download, MODELS_DIR, \"Checkpoints\")\n\n#LoRa download\n\nlora_to_download = [\n    (\"Detailer IL V2 218 MB\",        \"https://civitai.com/api/download/models/1736373?type=Model&format=SafeTensor\",    \"detailer_v2_il.safetensors\",     \"CIVITAI\"),\n    (\"Realistic filter V1 55 MB\",    \"https://civitai.com/api/download/models/1124771?type=Model&format=SafeTensor\",    \"realistic_filter_v1_il.safetensors\", \"CIVITAI\"),\n    (\"Hyperrealistic V4 ILL 435 MB\", \"https://civitai.com/api/download/models/1914557?type=Model&format=SafeTensor\",    \"hyperrealistic_v4_ill.safetensors\",  \"CIVITAI\"),\n    (\"Niji semi realism V3.5 ILL 435 MB\", \"https://civitai.com/api/download/models/1882710?type=Model&format=SafeTensor\", \"niji_v35.safetensors\", \"CIVITAI\"),\n    (\"ATNR Style ILL V1.1 350 MB\", \"https://civitai.com/api/download/models/1711464?type=Model&format=SafeTensor\", \"atnr_style_ill_v1.1.safetensors\", \"CIVITAI\"),\n    (\"Face Enhancer Ill 218 MB\", \"https://civitai.com/api/download/models/1839268?type=Model&format=SafeTensor\", \"face_enhancer_ill.safetensors\", \"CIVITAI\"),\n    (\"Smooth Detailer Booster V4 243 MB\", \"https://civitai.com/api/download/models/2196453?type=Model&format=SafeTensor\", \"smooth_detailer_booster_v4.safetensors\", \"CIVITAI\"),\n    (\"USNR Style V-pred 157 MB\", \"https://civitai.com/api/download/models/2555444?type=Model&format=SafeTensor\", \"usnr_style.safetensors\", \"CIVITAI\"),\n    (\"748cm Style V1 243 MB\", \"https://civitai.com/api/download/models/1056404?type=Model&format=SafeTensor\", \"748cm_style_v1.safetensors\", \"CIVITAI\"),\n    (\"Velvet's Mythic Fantasy Styles IL 218 MB\", \"https://civitai.com/api/download/models/2620790?type=Model&format=SafeTensor\", \"velvets_styles.safetensors\", \"CIVITAI\"),\n    (\"Pixel Art Style IL V7 435 MB\", \"https://civitai.com/api/download/models/2661972?type=Model&format=SafeTensor\", \"pixel_art.safetensors\", \"CIVITAI\"),\n]\n\nrun_download_list(lora_to_download, LORA_DIR, \"LoRA\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T14:22:44.763230Z","iopub.execute_input":"2026-02-17T14:22:44.763828Z","iopub.status.idle":"2026-02-17T14:23:49.764686Z","shell.execute_reply.started":"2026-02-17T14:22:44.763766Z","shell.execute_reply":"2026-02-17T14:23:49.763770Z"}},"outputs":[{"name":"stdout","text":"ControlNet extension path: /kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet\nInstall mode: reinstall\nCloning ControlNet repository...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet'...\n","output_type":"stream"},{"name":"stdout","text":"ControlNet repository is ready\nControlNet models directory: /kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet/models\n\n=== ControlNet ===\nParallel downloads: 3\n[DOWNLOADING] t2i-adapter_xl_openpose 151 MB\n[DOWNLOADING] t2i-adapter_xl_canny 148 MB\n[DOWNLOADING] t2i-adapter_xl_sketch 148 MB\n[DOWNLOADING] t2i-adapter_diffusers_xl_depth_midas 151 MB[OK]   t2i-adapter_xl_sketch 148 MB -> 147.9 MB\n\n[DOWNLOADING] t2i-adapter_diffusers_xl_depth_zoe 151 MB\n[OK]   t2i-adapter_xl_canny 148 MB -> 147.9 MB\n[OK]   t2i-adapter_xl_openpose 151 MB -> 150.7 MB\n[DOWNLOADING] t2i-adapter_diffusers_xl_lineart 151 MB\n[OK]   t2i-adapter_diffusers_xl_depth_zoe 151 MB -> 150.7 MB\n[OK]   t2i-adapter_diffusers_xl_lineart 151 MB -> 150.7 MB\n[OK]   t2i-adapter_diffusers_xl_depth_midas 151 MB -> 150.7 MB\nDone: OK=6, FAIL=0\n\n=== Checkpoints ===\nParallel downloads: 1\n[DOWNLOADING] WAI ILL V16.0 6,46 GB\n[OK]   WAI ILL V16.0 6,46 GB -> 6616.6 MB\nDone: OK=1, FAIL=0\n\n=== LoRA ===\nParallel downloads: 3\n[DOWNLOADING] Realistic filter V1 55 MB\n[DOWNLOADING] Hyperrealistic V4 ILL 435 MB\n[DOWNLOADING] Detailer IL V2 218 MB\n[OK]   Realistic filter V1 55 MB -> 54.8 MB[DOWNLOADING] Niji semi realism V3.5 ILL 435 MB\n\n[DOWNLOADING] ATNR Style ILL V1.1 350 MB[OK]   Detailer IL V2 218 MB -> 217.9 MB\n\n[OK]   Hyperrealistic V4 ILL 435 MB -> 435.4 MB[DOWNLOADING] Face Enhancer Ill 218 MB\n\n[OK]   Face Enhancer Ill 218 MB -> 217.9 MB[DOWNLOADING] Smooth Detailer Booster V4 243 MB\n\n[DOWNLOADING] USNR Style V-pred 157 MB[OK]   ATNR Style ILL V1.1 350 MB -> 350.2 MB\n\n[OK]   Niji semi realism V3.5 ILL 435 MB -> 435.4 MB\n[DOWNLOADING] 748cm Style V1 243 MB\n[DOWNLOADING] Velvet's Mythic Fantasy Styles IL 218 MB\n[OK]   Smooth Detailer Booster V4 243 MB -> 243.2 MB\n[OK]   USNR Style V-pred 157 MB -> 156.9 MB\n[DOWNLOADING] Pixel Art Style IL V7 435 MB\n[OK]   748cm Style V1 243 MB -> 243.2 MB\n[OK]   Velvet's Mythic Fantasy Styles IL 218 MB -> 217.9 MB\n  WARNING: file size looks low (217.9 MB vs expected ~435.0 MB)\n[OK]   Pixel Art Style IL V7 435 MB -> 217.9 MB\nDone: OK=11, FAIL=0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":["### RUN WEBUI (PURE PYTHON, BACKGROUND MODE) ###\n","\n","import os\n","import re\n","import time\n","import subprocess\n","from pathlib import Path\n","\n","forge_dir = Path(FORGE_DIR)\n","if not forge_dir.exists():\n","    raise FileNotFoundError(f\"FORGE_DIR не найден: {forge_dir}\")\n","\n","launch_utils_path = forge_dir / \"modules\" / \"launch_utils.py\"\n","if launch_utils_path.exists():\n","    content = launch_utils_path.read_text(encoding=\"utf-8\")\n","\n","    clip_line_pattern = re.compile(\n","        r'^(?P<indent>\\s*)run_pip\\(f\"install(?: --no-build-isolation)?(?: --no-use-pep517)? \\{clip_package\\}\", \"clip\"\\)\\s*$',\n","        re.MULTILINE,\n","    )\n","\n","    def _replace_clip_install(match):\n","        indent = match.group(\"indent\")\n","        return (\n","            f'{indent}run_pip(\"install setuptools==69.5.1 wheel\", \"clip build deps\")\\n'\n","            f'{indent}run_pip(f\"install --no-build-isolation {{clip_package}}\", \"clip\")'\n","        )\n","\n","    content_new, replacements = clip_line_pattern.subn(_replace_clip_install, content, count=1)\n","\n","    numpy_fix_pattern = re.compile(\n","        r'^(?P<indent>\\s*)startup_timer\\.record\\(\"install torch\"\\)\\s*$',\n","        re.MULTILINE,\n","    )\n","\n","    def _replace_torch_record(match):\n","        indent = match.group(\"indent\")\n","        return (\n","            f'{indent}run_pip(\"install \\\"numpy==2.2.6\\\" \\\"scikit-image>=0.24.0\\\" --force-reinstall\", \"numpy/skimage compatibility\")\\n'\n","            f'{indent}startup_timer.record(\"install torch\")'\n","        )\n","\n","    torch_fix_replacements = 0\n","    if \"numpy/skimage compatibility\" not in content_new:\n","        content_new, torch_fix_replacements = numpy_fix_pattern.subn(_replace_torch_record, content_new, count=1)\n","        if torch_fix_replacements:\n","            print(\"Patched torch stage (reinstalled numpy 2.x + scikit-image for ABI compatibility).\")\n","        else:\n","            print(\"Torch-stage compatibility patch not applied (marker not found).\")\n","\n","    late_numpy_pattern = re.compile(r'^(?P<indent>\\s*)import webui(?:\\s*#.*)?\\s*$', re.MULTILINE)\n","\n","    def _replace_import_webui(match):\n","        indent = match.group(\"indent\")\n","        return (\n","            f'{indent}run_pip(\"install \\\"numpy==2.2.6\\\" \\\"scikit-image>=0.24.0\\\" --force-reinstall\", \"numpy/skimage late compatibility\")\\n'\n","            f'{indent}import webui'\n","        )\n","\n","    late_fix_replacements = 0\n","    if \"numpy/skimage late compatibility\" not in content_new:\n","        content_new, late_fix_replacements = late_numpy_pattern.subn(_replace_import_webui, content_new, count=1)\n","        if late_fix_replacements:\n","            print(\"Patched start stage (re-pin numpy/scikit-image before importing webui).\")\n","        else:\n","            print(\"Start-stage compatibility patch not applied (import webui line not found).\")\n","\n","    if replacements or torch_fix_replacements or late_fix_replacements:\n","        launch_utils_path.write_text(content_new, encoding=\"utf-8\")\n","\n","    if replacements:\n","        print(\"Patched CLIP install command (fixed flags + preserved indentation).\")\n","    else:\n","        print(\"CLIP install patch already applied or target line not found.\")\n","else:\n","    print(f\"Warning: {launch_utils_path} not found, skipping CLIP patch.\")\n","\n","# Workaround for frequent startup issue in ControlNet: soft_inpainting.py\n","soft_inpainting_path = forge_dir / \"extensions\" / \"sd-webui-controlnet\" / \"scripts\" / \"soft_inpainting.py\"\n","soft_inpainting_disabled_path = soft_inpainting_path.with_suffix(\".py.disabled\")\n","if soft_inpainting_path.exists():\n","    os.replace(soft_inpainting_path, soft_inpainting_disabled_path)\n","    print(f\"Disabled problematic script: {soft_inpainting_path.name} -> {soft_inpainting_disabled_path.name}\")\n","else:\n","    print(\"soft_inpainting.py already disabled or not present.\")\n","\n","cmd = [\"bash\", \"webui.sh\", \"-f\", \"--xformers\", \"--api\", \"--port\", \"17860\"]\n","run_env = os.environ.copy()\n","run_env[\"MPLBACKEND\"] = \"Agg\"\n","print(\"Running (background):\", \" \".join(cmd), \"in\", forge_dir)\n","print(\"MPLBACKEND forced to:\", run_env[\"MPLBACKEND\"])\n","\n","venv_python = forge_dir / \"venv\" / \"bin\" / \"python\"\n","if venv_python.exists():\n","    print(\"Installing missing dependency in Forge venv: joblib\")\n","    subprocess.run([str(venv_python), \"-m\", \"pip\", \"install\", \"joblib\"], check=False)\n","\n","    print(\"Trying optional dependency in Forge venv: insightface\")\n","    insightface_result = subprocess.run([str(venv_python), \"-m\", \"pip\", \"install\", \"insightface\"], check=False)\n","    if insightface_result.returncode != 0:\n","        print(\"Warning: insightface installation failed (optional dependency).\")\n","else:\n","    print(f\"Warning: venv python not found at {venv_python}, skipping joblib/insightface install.\")\n","\n","pid_path = forge_dir / \"webui.pid\"\n","log_path = forge_dir / \"webui.log\"\n","\n","\n","def _pid_alive(pid: int) -> bool:\n","    try:\n","        os.kill(pid, 0)\n","        return True\n","    except Exception:\n","        return False\n","\n","\n","def _log_tail(chars: int = 4000) -> str:\n","    if not log_path.exists():\n","        return \"(webui.log not found yet)\"\n","    return log_path.read_text(encoding=\"utf-8\", errors=\"ignore\")[-chars:]\n","\n","\n","running_pid = None\n","if pid_path.exists():\n","    try:\n","        old_pid = int(pid_path.read_text(encoding=\"utf-8\").strip())\n","        if _pid_alive(old_pid):\n","            running_pid = old_pid\n","            print(f\"WebUI already running with PID={old_pid}. Можно запускать последнюю ячейку.\")\n","        else:\n","            pid_path.unlink(missing_ok=True)\n","    except Exception:\n","        pid_path.unlink(missing_ok=True)\n","\n","started_proc = None\n","if running_pid is None:\n","    with open(log_path, \"a\", encoding=\"utf-8\") as log_f:\n","        started_proc = subprocess.Popen(\n","            cmd,\n","            cwd=forge_dir,\n","            env=run_env,\n","            stdout=log_f,\n","            stderr=subprocess.STDOUT,\n","            start_new_session=True,\n","            text=True,\n","        )\n","    pid_path.write_text(str(started_proc.pid), encoding=\"utf-8\")\n","    running_pid = started_proc.pid\n","    print(f\"WebUI started in background. PID={running_pid}\")\n","    print(f\"Logs: {log_path}\")\n","\n","observe_timeout = int(os.environ.get(\"FORGE_STARTUP_OBSERVE_TIMEOUT\", \"120\"))\n","observe_interval = float(os.environ.get(\"FORGE_STARTUP_OBSERVE_INTERVAL\", \"2\"))\n","\n","for _ in range(max(1, int(observe_timeout / observe_interval))):\n","    tail = _log_tail()\n","\n","    if started_proc is not None:\n","        rc = started_proc.poll()\n","        if rc is not None:\n","            raise RuntimeError(\n","                f\"WebUI process exited early with code {rc}.\\n\"\n","                f\"Check logs at: {log_path}\\n\"\n","                f\"Last log lines:\\n{tail}\"\n","            )\n","\n","    if \"Running on local URL\" in tail or \"Uvicorn running\" in tail:\n","        print(\"WebUI appears ready. Можно запускать последнюю ячейку.\")\n","        break\n","\n","    time.sleep(observe_interval)\n","else:\n","    print(\"WebUI всё ещё запускается в фоне. Запускайте последнюю ячейку: она дождётся API.\")\n","    print(f\"Если API не поднимется, проверьте лог: {log_path}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpZBUyZoYFHL","executionInfo":{"status":"ok","timestamp":1771328692825,"user_tz":-120,"elapsed":188283,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"9fa9759a-2652-4c2e-d911-73a85dcf233c","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T14:23:54.682252Z","iopub.execute_input":"2026-02-17T14:23:54.683078Z","execution_failed":"2026-02-17T14:29:27.215Z"}},"outputs":[{"name":"stdout","text":"Patched torch stage (reinstalled numpy 2.x + scikit-image for ABI compatibility).\nPatched start stage (re-pin numpy/scikit-image before importing webui).\nPatched CLIP install command (fixed flags + preserved indentation).\nRunning: bash webui.sh -f --xformers --api --port 17860 in /kaggle/working/stable-diffusion-webui-forge\nMPLBACKEND forced to: Agg\nWarning: venv python not found at /kaggle/working/stable-diffusion-webui-forge/venv/bin/python, skipping joblib/insightface install.\n\n################################################################\n\u001b[1m\u001b[32mInstall script for stable-diffusion + Web UI\n\u001b[1m\u001b[34mTested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.\u001b[0m\n################################################################\n\n################################################################\nRunning on \u001b[1m\u001b[32mroot\u001b[0m user\n################################################################\n\n################################################################\nRepo already cloned, using it as install directory\n################################################################\n\n################################################################\nCreate and activate python venv\n################################################################\nRequirement already satisfied: pip in ./venv/lib/python3.10/site-packages (22.0.2)\nCollecting pip\n  Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 10.2 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 22.0.2\n    Uninstalling pip-22.0.2:\n      Successfully uninstalled pip-22.0.2\nSuccessfully installed pip-26.0.1\n\n################################################################\nLaunching launch.py...\n################################################################\nglibc version is 2.35\nCheck TCMalloc: libtcmalloc_minimal.so.4\nlibtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\nPython 3.10.12 (main, Jan 26 2026, 14:55:28) [GCC 11.4.0]\nVersion: f2.0.1v1.10.1-previous-669-gdfdcbab6\nCommit hash: dfdcbab685e57677014f05a3309b48cc87383167\nInstalling torch and torchvision\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.0/781.0 MB 54.7 MB/s  0:00:06\nCollecting torchvision==0.18.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 105.8 MB/s  0:00:00\nCollecting filelock (from torch==2.3.1)\n  Downloading filelock-3.24.2-py3-none-any.whl.metadata (2.0 kB)\nCollecting typing-extensions>=4.8.0 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting sympy (from torch==2.3.1)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting networkx (from torch==2.3.1)\n  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting jinja2 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting fsspec (from torch==2.3.1)\n  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 124.6 MB/s  0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 35.9 MB/s  0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 117.6 MB/s  0:00:00\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 43.2 MB/s  0:00:08\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 76.5 MB/s  0:00:04\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 108.3 MB/s  0:00:01\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 116.3 MB/s  0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 106.3 MB/s  0:00:01\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 99.1 MB/s  0:00:01\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 99.7 MB/s  0:00:01\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nCollecting triton==2.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.1/168.1 MB 105.7 MB/s  0:00:01\nCollecting numpy (from torchvision==0.18.1)\n  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.18.1)\n  Downloading pillow-12.1.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch==2.3.1)\n  Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.1)\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nDownloading pillow-12.1.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 83.2 MB/s  0:00:00\nDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nDownloading filelock-3.24.2-py3-none-any.whl (24 kB)\nDownloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\nDownloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\nDownloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\nDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 37.3 MB/s  0:00:00\nDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 119.1 MB/s  0:00:00\nDownloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 133.7 MB/s  0:00:00\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 91.7 MB/s  0:00:00\nDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 21.1 MB/s  0:00:00\nInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n\nSuccessfully installed MarkupSafe-3.0.3 filelock-3.24.2 fsspec-2026.2.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-12.1.1 sympy-1.14.0 torch-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1 typing-extensions-4.15.0\nInstalling numpy/skimage compatibility\nInstalling clip build deps\nInstalling clip\nInstalling open_clip\nInstalling xformers\nCloning assets into /kaggle/working/stable-diffusion-webui-forge/repositories/stable-diffusion-webui-assets...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge/repositories/stable-diffusion-webui-assets'...\n","output_type":"stream"},{"name":"stdout","text":"Cloning huggingface_guess into /kaggle/working/stable-diffusion-webui-forge/repositories/huggingface_guess...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge/repositories/huggingface_guess'...\n","output_type":"stream"},{"name":"stdout","text":"Cloning BLIP into /kaggle/working/stable-diffusion-webui-forge/repositories/BLIP...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge/repositories/BLIP'...\n","output_type":"stream"},{"name":"stdout","text":"Installing requirements\nInstalling sd-forge-controlnet requirement: fvcore\nInstalling sd-forge-controlnet requirement: mediapipe\nInstalling sd-forge-controlnet requirement: onnxruntime\nInstalling sd-forge-controlnet requirement: svglib\nLegacy Preprocessor init warning: Unable to install insightface automatically. Please try run `pip install insightface` manually.\nInstalling forge_legacy_preprocessor requirement: handrefinerportable\nInstalling forge_legacy_preprocessor requirement: depth_anything\nInstalling forge_legacy_preprocessor requirement: depth_anything_v2\nLaunching Web UI with arguments: -f --xformers --api --port 17860\nInstalling numpy/skimage late compatibility\nTotal VRAM 14913 MB, total RAM 32103 MB\npytorch version: 2.3.1+cu121\nxformers version: 0.0.27\nSet vram state to: NORMAL_VRAM\nDevice: cuda:0 Tesla T4 : native\nVAE dtype preferences: [torch.float32] -> torch.float32\nInstalling bitsandbytes==0.45.3\nCUDA Using Stream: False\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Using xformers cross attention\nUsing xformers attention for VAE\nControlNet preprocessor location: /kaggle/working/stable-diffusion-webui-forge/models/ControlNetPreprocessor\n","output_type":"stream"},{"name":"stderr","text":"*** Error loading script: soft_inpainting.py\n    Traceback (most recent call last):\n      File \"/kaggle/working/stable-diffusion-webui-forge/modules/scripts.py\", line 525, in load_scripts\n        script_module = script_loading.load_module(scriptfile.path)\n      File \"/kaggle/working/stable-diffusion-webui-forge/modules/script_loading.py\", line 13, in load_module\n        module_spec.loader.exec_module(module)\n      File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n      File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n      File \"/kaggle/working/stable-diffusion-webui-forge/extensions-builtin/soft-inpainting/scripts/soft_inpainting.py\", line 10, in <module>\n        from joblib import Parallel, delayed, cpu_count\n    ModuleNotFoundError: No module named 'joblib'\n\n---\n","output_type":"stream"},{"name":"stdout","text":"2026-02-17 14:29:03,812 - ControlNet - \u001b[0;32mINFO\u001b[0m - ControlNet UI callback registered.\nModel selected: {'checkpoint_info': {'filename': '/kaggle/working/stable-diffusion-webui-forge/models/Stable-diffusion/wai_v160.safetensors', 'hash': '4748a7f6'}, 'additional_modules': [], 'unet_storage_dtype': None}\nUsing online LoRAs in FP16: False\nRunning on local URL:  http://127.0.0.1:17860\n\nTo create a public link, set `share=True` in `launch()`.\nStartup time: 307.9s (prepare environment: 270.6s, launcher: 13.5s, import torch: 11.8s, initialize shared: 0.2s, other imports: 0.5s, list SD models: 0.6s, load scripts: 2.7s, create ui: 4.8s, gradio launch: 1.6s, add APIs: 1.6s).\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":["### API GENERATION FROM XLSX ###\n","\n","import os\n","import re\n","import json\n","import glob\n","import time\n","import shutil\n","import zipfile\n","import base64\n","from datetime import datetime\n","\n","import requests\n","from openpyxl import load_workbook\n","\n","API_BASE = os.environ.get(\"FORGE_API_BASE\", \"http://127.0.0.1:17860\")\n","TXT2IMG_URL = f\"{API_BASE}/sdapi/v1/txt2img\"\n","OPENAPI_URL = f\"{API_BASE}/openapi.json\"\n","\n","PROMPTS_CANDIDATES = [\n","    os.path.join(GEN_DIR, \"prompts.xlsx\"),\n","    os.path.join(GEN_DIR, \"prompts.xlxs\"),\n","    os.path.join(GEN_DIR, \"Prompts.xlsx\"),\n","    os.path.join(GEN_DIR, \"Prompts.xlxs\"),\n","    os.path.join(BASE_DIR, \"prompts.xlsx\"),\n","    os.path.join(BASE_DIR, \"prompts.xlxs\"),\n","    os.path.join(BASE_DIR, \"Prompts.xlsx\"),\n","    os.path.join(BASE_DIR, \"Prompts.xlxs\"),\n","    \"/workspace/gen/prompts.xlsx\",\n","    \"/workspace/gen/prompts.xlxs\",\n","]\n","\n","if ON_COLAB:\n","    # Colab manual upload often lands in /content\n","    PROMPTS_CANDIDATES.extend([\n","        \"/content/prompts.xlsx\",\n","        \"/content/prompts.xlxs\",\n","        \"/content/Prompts.xlsx\",\n","        \"/content/Prompts.xlxs\",\n","    ])\n","\n","if ON_KAGGLE:\n","    # Fixed Kaggle dataset path used in your workflow\n","    PROMPTS_CANDIDATES.append(\"/kaggle/input/datasets/sokolenkotimofei/prompts/Prompts.xlsx\")\n","\n","    # Additional Kaggle dataset input path patterns (fallback)\n","    for pattern in [\n","        \"/kaggle/input/*/*/prompts/prompts.xlsx\",\n","        \"/kaggle/input/*/*/prompts/prompts.xlxs\",\n","        \"/kaggle/input/*/*/prompts/Prompts.xlsx\",\n","        \"/kaggle/input/*/*/prompts/Prompts.xlxs\",\n","        \"/kaggle/input/*/prompts/prompts.xlsx\",\n","        \"/kaggle/input/*/prompts/prompts.xlxs\",\n","        \"/kaggle/input/*/prompts/Prompts.xlsx\",\n","        \"/kaggle/input/*/prompts/Prompts.xlxs\",\n","    ]:\n","        PROMPTS_CANDIDATES.extend(sorted(glob.glob(pattern)))\n","\n","# Keep order, remove duplicates\n","PROMPTS_CANDIDATES = list(dict.fromkeys(PROMPTS_CANDIDATES))\n","\n","API_READY_TIMEOUT = int(os.environ.get(\"FORGE_API_READY_TIMEOUT\", \"600\"))\n","API_READY_INTERVAL = float(os.environ.get(\"FORGE_API_READY_INTERVAL\", \"3\"))\n","\n","\n","def wait_for_api_ready(base_url: str, timeout_s: int = API_READY_TIMEOUT, interval_s: float = API_READY_INTERVAL):\n","    start = time.time()\n","    last_error = None\n","    webui_log = os.path.join(FORGE_DIR, \"webui.log\")\n","    webui_pid = os.path.join(FORGE_DIR, \"webui.pid\")\n","\n","    def _log_tail(chars: int = 4000):\n","        if not os.path.exists(webui_log):\n","            return \"(webui.log not found yet)\"\n","        with open(webui_log, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","            return f.read()[-chars:]\n","\n","    def _is_pid_alive():\n","        try:\n","            if not os.path.exists(webui_pid):\n","                return None\n","            with open(webui_pid, \"r\", encoding=\"utf-8\") as f:\n","                pid = int(f.read().strip())\n","            os.kill(pid, 0)\n","            return pid\n","        except Exception:\n","            return False\n","\n","    while (time.time() - start) < timeout_s:\n","        try:\n","            r = requests.get(f\"{base_url}/sdapi/v1/progress\", timeout=10)\n","            if r.status_code < 500:\n","                return True\n","            last_error = f\"HTTP {r.status_code}\"\n","        except Exception as e:\n","            last_error = str(e)\n","\n","        pid_state = _is_pid_alive()\n","        if pid_state is False:\n","            raise RuntimeError(\n","                \"Forge API недоступен и процесс WebUI уже завершился.\\n\"\n","                f\"Last error: {last_error}\\n\"\n","                f\"WebUI log tail:\\n{_log_tail()}\"\n","            )\n","\n","        time.sleep(interval_s)\n","\n","    raise RuntimeError(\n","        f\"Forge API is not reachable at {base_url} after {timeout_s}s. \"\n","        f\"Last error: {last_error}.\\n\"\n","        f\"WebUI log tail:\\n{_log_tail()}\\n\"\n","        \"Run the Forge startup cell first. If this is first launch, increase FORGE_API_READY_TIMEOUT (e.g. 900).\"\n","    )\n","\n","\n","LOG_PATH = os.path.join(VOLUME_DIR, \"log.txt\")\n","API_IMAGES_DIR = os.path.join(OUTPUTS_DIR, \"api_generated\")\n","os.makedirs(API_IMAGES_DIR, exist_ok=True)\n","\n","\n","CONFLICT_RULES = [\n","    ((\"hr_resize_x\", \"hr_resize_y\"), (\"hr_scale\",)),\n","]\n","\n","\n","def log_line(text: str):\n","    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    line = f\"[{ts}] {text}\"\n","    print(line)\n","    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n","        f.write(line + \"\\n\")\n","\n","\n","def normalize_value(value):\n","    if isinstance(value, str):\n","        stripped = value.strip()\n","        lowered = stripped.lower()\n","        if lowered in {\"\", \"null\", \"none\", \"nan\"}:\n","            return None\n","        if lowered in {\"true\", \"yes\", \"1\"}:\n","            return True\n","        if lowered in {\"false\", \"no\", \"0\"}:\n","            return False\n","        if re.fullmatch(r\"-?\\d+\", stripped):\n","            return int(stripped)\n","        if re.fullmatch(r\"-?\\d+\\.\\d+\", stripped):\n","            return float(stripped)\n","        return stripped\n","    return value\n","\n","\n","def first_existing_path(candidates):\n","    for p in candidates:\n","        if os.path.exists(p):\n","            return p\n","    return None\n","\n","\n","def parse_workbook(path):\n","    wb = load_workbook(path, data_only=True)\n","    ws = wb.active\n","\n","    instruction_parts = [str(v).strip() for v in ws[1] if v is not None and str(v).strip()]\n","    if not instruction_parts:\n","        raise ValueError(\"Первая строка (инструкция) пустая\")\n","    instruction = \" \".join(instruction_parts)\n","\n","    headers = [str(v).strip() if v is not None else \"\" for v in ws[2]]\n","    if not any(headers):\n","        raise ValueError(\"Вторая строка должна содержать имена переменных (заголовки столбцов)\")\n","\n","    rows = []\n","    for row_idx in range(3, ws.max_row + 1):\n","        row_values = [normalize_value(v) for v in next(ws.iter_rows(min_row=row_idx, max_row=row_idx, values_only=True))]\n","        if all(v is None for v in row_values):\n","            continue\n","\n","        row_map = {}\n","        for idx, key in enumerate(headers):\n","            if not key:\n","                continue\n","            value = row_values[idx] if idx < len(row_values) else None\n","            if value is None:\n","                continue\n","            row_map[key] = value\n","        rows.append(row_map)\n","\n","    if not rows:\n","        raise ValueError(\"Не найдено строк данных (начиная с 3-й строки)\")\n","\n","    return instruction, rows\n","\n","\n","def render_instruction(template: str, variables: dict):\n","    def repl(match):\n","        key = match.group(1)\n","        return str(variables.get(key, match.group(0)))\n","    return re.sub(r\"\\{([a-zA-Z0-9_]+)\\}\", repl, template)\n","\n","\n","def apply_conflict_rules(payload: dict):\n","    cleaned = dict(payload)\n","    for primary_keys, conflicting_keys in CONFLICT_RULES:\n","        primary_present = all((k in cleaned and cleaned[k] is not None) for k in primary_keys)\n","        if primary_present:\n","            for ck in conflicting_keys:\n","                cleaned.pop(ck, None)\n","    return cleaned\n","\n","\n","def fetch_txt2img_params_dump():\n","    try:\n","        response = requests.get(OPENAPI_URL, timeout=30)\n","        response.raise_for_status()\n","        spec = response.json()\n","        schemas = spec.get(\"components\", {}).get(\"schemas\", {})\n","        candidates = [\n","            \"StableDiffusionTxt2ImgProcessingApi\",\n","            \"Txt2ImgRequest\",\n","            \"StableDiffusionProcessingTxt2Img\",\n","        ]\n","        for name in candidates:\n","            if name in schemas:\n","                props = schemas[name].get(\"properties\", {})\n","                return json.dumps({k: v.get(\"type\", \"unknown\") for k, v in props.items()}, ensure_ascii=False, indent=2)\n","        return json.dumps(spec.get(\"paths\", {}).get(\"/sdapi/v1/txt2img\", {}), ensure_ascii=False, indent=2)\n","    except Exception as e:\n","        return f\"Не удалось получить список переменных: {e}\"\n","\n","\n","def save_images_from_response(images_b64, generation_idx):\n","    saved = 0\n","    for i, b64 in enumerate(images_b64, start=1):\n","        image_data = b64.split(\",\", 1)[-1]\n","        file_name = f\"gen_{generation_idx:04d}_{i:02d}.png\"\n","        file_path = os.path.join(API_IMAGES_DIR, file_name)\n","        with open(file_path, \"wb\") as f:\n","            f.write(base64.b64decode(image_data))\n","        saved += 1\n","    return saved\n","\n","\n","def archive_outputs(tag: str):\n","    stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    archive_name = os.path.join(VOLUME_DIR, f\"outputs_{tag}_{stamp}.zip\")\n","    with zipfile.ZipFile(archive_name, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n","        for root, _, files in os.walk(OUTPUTS_DIR):\n","            for file in files:\n","                full_path = os.path.join(root, file)\n","                rel_path = os.path.relpath(full_path, OUTPUTS_DIR)\n","                zf.write(full_path, rel_path)\n","\n","    for entry in os.listdir(OUTPUTS_DIR):\n","        p = os.path.join(OUTPUTS_DIR, entry)\n","        if os.path.isdir(p):\n","            shutil.rmtree(p)\n","        else:\n","            os.remove(p)\n","    os.makedirs(API_IMAGES_DIR, exist_ok=True)\n","    log_line(f\"ARCHIVE created: {archive_name}. OUTPUTS_DIR cleaned.\")\n","\n","\n","wait_for_api_ready(API_BASE)\n","\n","prompts_path = first_existing_path(PROMPTS_CANDIDATES)\n","if not prompts_path:\n","    raise FileNotFoundError(\n","        \"Файл prompts.xlsx/prompts.xlxs не найден. Ожидались пути: \" + \", \".join(PROMPTS_CANDIDATES)\n","    )\n","\n","instruction_template, generation_rows = parse_workbook(prompts_path)\n","log_line(f\"Loaded prompts file: {prompts_path}. Rows for generation: {len(generation_rows)}\")\n","\n","syntax_error_dumped = False\n","images_since_archive = 0\n","\n","for generation_idx, row_values in enumerate(generation_rows, start=1):\n","    payload = dict(row_values)\n","\n","    if \"prompt\" not in payload:\n","        payload[\"prompt\"] = render_instruction(instruction_template, row_values)\n","\n","    payload = {k: v for k, v in payload.items() if v is not None}\n","    payload = apply_conflict_rules(payload)\n","\n","    try:\n","        response = requests.post(TXT2IMG_URL, json=payload, timeout=1800)\n","        if response.status_code >= 400:\n","            err_text = response.text[:1200]\n","            if not syntax_error_dumped:\n","                params_dump = fetch_txt2img_params_dump()\n","                log_line(f\"#{generation_idx} FAIL syntax/validation: {response.status_code} {err_text}\")\n","                log_line(\"AVAILABLE PARAMS DUMP START\")\n","                with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n","                    f.write(params_dump + \"\\n\")\n","                log_line(\"AVAILABLE PARAMS DUMP END\")\n","                syntax_error_dumped = True\n","            else:\n","                log_line(f\"#{generation_idx} FAIL: {response.status_code} {err_text}\")\n","            continue\n","\n","        result = response.json()\n","        images = result.get(\"images\", []) or []\n","        saved_now = save_images_from_response(images, generation_idx)\n","        images_since_archive += saved_now\n","        log_line(f\"#{generation_idx} OK images={saved_now}\")\n","\n","        if images_since_archive >= 15:\n","            archive_outputs(tag=f\"part_{generation_idx:04d}\")\n","            images_since_archive = 0\n","\n","    except requests.exceptions.Timeout:\n","        log_line(f\"#{generation_idx} FAIL: timeout (possible heavy generation or API freeze)\")\n","    except requests.exceptions.RequestException as e:\n","        reason = str(e)\n","        if \"out of memory\" in reason.lower() or \"oom\" in reason.lower():\n","            reason = \"OOM\"\n","        log_line(f\"#{generation_idx} FAIL: {reason}\")\n","    except Exception as e:\n","        log_line(f\"#{generation_idx} FAIL: unexpected error: {e}\")\n","\n","if images_since_archive > 0:\n","    archive_outputs(tag=\"final\")\n","\n","log_line(\"Generation cycle completed\")"],"metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-17T14:29:27.216Z"}},"outputs":[],"execution_count":null}]}
