{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "Multi-platform loading",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "###SETTINGS###\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import shutil\n",
    "from getpass import getpass\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Platform detection\n",
    "ON_KAGGLE = os.path.exists('/kaggle')\n",
    "ON_COLAB = 'COLAB_RELEASE_TAG' in os.environ or os.path.exists('/content')\n",
    "ON_VAST = any(k in os.environ for k in (\"VAST_CONTAINERLABEL\", \"VAST_TCP_PORT_22\", \"CONTAINER_ID\")) or os.path.exists('/workspace')\n",
    "\n",
    "if shutil.which(\"aria2c\") is None:\n",
    "    print(\"aria2c not found → installing...\")\n",
    "    try:\n",
    "        subprocess.run([\"apt\", \"update\", \"-qq\"], check=True, capture_output=True)\n",
    "        result = subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", \"aria2\"], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"aria2c installed successfully\")\n",
    "        else:\n",
    "            print(\"Install failed (code {}):\".format(result.returncode))\n",
    "            print(\"stderr:\", result.stderr.strip())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"apt error (code {e.returncode}): {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "else:\n",
    "    print(\"aria2c already available\")\n",
    "\n",
    "# Determining the working directory\n",
    "possible_bases = [\n",
    "    \"/workspace\",       # Vast.ai / RunPod\n",
    "    \"/kaggle/working\",  # Kaggle\n",
    "    \"/content\",         # Google Colab\n",
    "]\n",
    "\n",
    "BASE_DIR = None\n",
    "for path in possible_bases:\n",
    "    if os.path.isdir(path):\n",
    "        BASE_DIR = path\n",
    "        break\n",
    "\n",
    "if BASE_DIR is None:\n",
    "    BASE_DIR = os.getcwd()\n",
    "    print(\"WARNING: Known directory not found:\", BASE_DIR)\n",
    "\n",
    "print(\"Working directory:\", BASE_DIR)\n",
    "\n",
    "# Configuration\n",
    "FORGE_DIR        = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\")\n",
    "MODELS_DIR       = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Stable-diffusion\")\n",
    "LORA_DIR         = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Lora\")\n",
    "CONTROLNET_DIR   = os.path.join(FORGE_DIR, \"extensions\", \"sd-webui-controlnet\")\n",
    "CONTROLNET_MODELS_DIR = os.path.join(CONTROLNET_DIR, \"models\")\n",
    "EXTENSIONS_DIR   = os.path.join(FORGE_DIR, \"extensions\")\n",
    "OUTPUTS_DIR      = os.path.join(FORGE_DIR, \"outputs\")\n",
    "\n",
    "for d in [MODELS_DIR, LORA_DIR, CONTROLNET_DIR, CONTROLNET_MODELS_DIR, EXTENSIONS_DIR, OUTPUTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "\n",
    "def get_secret(name: str):\n",
    "    \"\"\"Get secret from env/Kaggle/Colab, then optional prompt.\"\"\"\n",
    "    value = os.environ.get(name)\n",
    "    if value:\n",
    "        return value.strip(), \"env\"\n",
    "\n",
    "    # Kaggle secrets\n",
    "    if ON_KAGGLE:\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            value = UserSecretsClient().get_secret(name)\n",
    "            if value:\n",
    "                return value.strip(), \"kaggle_secrets\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Colab secrets panel: from google.colab import userdata\n",
    "    if ON_COLAB:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            value = userdata.get(name)\n",
    "            if value:\n",
    "                return value.strip(), \"colab_userdata\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Manual fallback for Vast.ai/local\n",
    "    try:\n",
    "        manual = getpass(f\"{name}: \").strip() or None\n",
    "        if manual:\n",
    "            return manual, \"manual_input\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "CIVITAI_TOKEN, CIVITAI_SRC = get_secret(\"CIVITAI_TOKEN\")\n",
    "HF_TOKEN, HF_SRC = get_secret(\"HF_TOKEN\")\n",
    "\n",
    "TOKENS = {}\n",
    "if CIVITAI_TOKEN:\n",
    "    TOKENS[\"CIVITAI\"] = CIVITAI_TOKEN\n",
    "if HF_TOKEN:\n",
    "    TOKENS[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "print(\"Token sources:\")\n",
    "print(f\"  CIVITAI_TOKEN: {CIVITAI_SRC or 'not found'}\")\n",
    "print(f\"  HF_TOKEN: {HF_SRC or 'not found'}\")\n",
    "if ON_VAST:\n",
    "    print(\"Vast.ai tip: add CIVITAI_TOKEN/HF_TOKEN in template env vars, restart container, then rerun this cell.\")\n",
    "\n",
    "if not CIVITAI_TOKEN:\n",
    "    print(\"CivitAI token not found\")\n",
    "if not HF_TOKEN:\n",
    "    print(\"HF token not found\")\n",
    "\n",
    "\n",
    "def _prepare_download_url(url, token):\n",
    "    \"\"\"CivitAI download works more reliably with token as query param.\"\"\"\n",
    "    if token and \"civitai.com/api/download/models\" in url and \"token=\" not in url:\n",
    "        sep = \"&\" if \"?\" in url else \"?\"\n",
    "        return f\"{url}{sep}{urlencode({'token': token})}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "def _looks_valid_file(path, min_bytes=1_000_000):\n",
    "    return os.path.exists(path) and os.path.getsize(path) > min_bytes\n",
    "\n",
    "\n",
    "def _human_mb(num_bytes):\n",
    "    return f\"{num_bytes / (1024 * 1024):.1f} MB\"\n",
    "\n",
    "\n",
    "def _estimate_expected_mb(label):\n",
    "    # Examples: \"151 MB\", \"6,46 GB\"\n",
    "    match = re.search(r\"(\\d+[\\.,]?\\d*)\\s*(MB|GB)\", label, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None\n",
    "    value = float(match.group(1).replace(',', '.'))\n",
    "    unit = match.group(2).upper()\n",
    "    return value * (1024 if unit == \"GB\" else 1)\n",
    "\n",
    "\n",
    "def _size_sanity_warning(path, expected_mb, tolerance=0.7):\n",
    "    if expected_mb is None or not os.path.exists(path):\n",
    "        return\n",
    "    actual_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "    if actual_mb < expected_mb * tolerance:\n",
    "        print(f\"  WARNING: file size looks low ({actual_mb:.1f} MB vs expected ~{expected_mb:.1f} MB)\")\n",
    "\n",
    "\n",
    "def download_file(url, output_path, token=None, expected_mb=None):\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    if _looks_valid_file(output_path):\n",
    "        print(f\"  Already ready → {_human_mb(os.path.getsize(output_path))}\")\n",
    "        return\n",
    "\n",
    "    token = token.strip() if isinstance(token, str) else token\n",
    "    final_url = _prepare_download_url(url, token)\n",
    "\n",
    "    attempts = []\n",
    "\n",
    "    if shutil.which(\"aria2c\"):\n",
    "        aria2_cmd = [\n",
    "            \"aria2c\", \"-x\", \"16\", \"-s\", \"16\", \"-k\", \"1M\",\n",
    "            \"--summary-interval=1\", \"--console-log-level=warn\",\n",
    "            \"--max-tries=3\", \"--retry-wait=2\", \"--continue=true\",\n",
    "            \"-d\", os.path.dirname(output_path),\n",
    "            \"-o\", os.path.basename(output_path),\n",
    "            final_url,\n",
    "        ]\n",
    "        if token:\n",
    "            aria2_cmd += [\"--header\", f\"Authorization: Bearer {token}\"]\n",
    "        attempts.append((\"aria2c\", aria2_cmd))\n",
    "\n",
    "    if shutil.which(\"curl\"):\n",
    "        curl_cmd = [\n",
    "            \"curl\", \"-L\", \"-C\", \"-\", \"--fail\", \"--progress-bar\",\n",
    "            \"--retry\", \"3\", \"--retry-delay\", \"2\",\n",
    "            \"-A\", \"Mozilla/5.0\",\n",
    "            final_url, \"-o\", output_path,\n",
    "        ]\n",
    "        if token:\n",
    "            curl_cmd = curl_cmd[:1] + [\"-H\", f\"Authorization: Bearer {token}\"] + curl_cmd[1:]\n",
    "        attempts.append((\"curl\", curl_cmd))\n",
    "\n",
    "    wget_cmd = [\n",
    "        \"wget\", \"-c\", final_url, \"-O\", output_path,\n",
    "        \"--tries=2\", \"--waitretry=2\",\n",
    "        \"--user-agent=Mozilla/5.0\",\n",
    "        \"--progress=dot:giga\",\n",
    "    ]\n",
    "    if token:\n",
    "        wget_cmd = wget_cmd[:2] + [\"--header\", f\"Authorization: Bearer {token}\"] + wget_cmd[2:]\n",
    "    attempts.append((\"wget\", wget_cmd))\n",
    "\n",
    "    last_error = None\n",
    "    for tool_name, cmd in attempts:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            print(f\"  [{tool_name}] started\")\n",
    "            subprocess.run(cmd, check=True)\n",
    "            elapsed = max(time.time() - start, 0.01)\n",
    "\n",
    "            if not _looks_valid_file(output_path):\n",
    "                raise RuntimeError(f\"{tool_name} finished but file is empty/small\")\n",
    "\n",
    "            size_bytes = os.path.getsize(output_path)\n",
    "            speed_mbps = (size_bytes * 8) / elapsed / 1_000_000\n",
    "            print(f\"  OK → {os.path.basename(output_path)} ({tool_name}, {_human_mb(size_bytes)}, ~{speed_mbps:.1f} Mbit/s)\")\n",
    "            _size_sanity_warning(output_path, expected_mb)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            last_error = e\n",
    "            if os.path.exists(output_path) and os.path.getsize(output_path) < 1_000_000:\n",
    "                try:\n",
    "                    os.remove(output_path)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            print(f\"  {tool_name} failed: {e}\")\n",
    "\n",
    "    raise RuntimeError(f\"All download methods failed for {output_path}. Last error: {last_error}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-13T16:13:46.019778Z",
     "iopub.execute_input": "2026-02-13T16:13:46.020872Z",
     "iopub.status.idle": "2026-02-13T16:14:07.794680Z",
     "shell.execute_reply.started": "2026-02-13T16:13:46.020816Z",
     "shell.execute_reply": "2026-02-13T16:14:07.793682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "aria2c not found → installing...\naria2c installed successfully\nWorking directory: /kaggle/working\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "### CONTROLNET INSTALL OPTIONS ###\n\n# Option A (default): force clean reinstall\n# Option B: set CONTROLNET_INSTALL_MODE = \"update\" for git pull in existing repo\n# Option C: set CONTROLNET_INSTALL_MODE = \"skip\" to keep current state\n\nCONTROLNET_REPO_URL = \"https://github.com/Mikubill/sd-webui-controlnet\"\nCONTROLNET_INSTALL_MODE = os.environ.get(\"CONTROLNET_INSTALL_MODE\", \"reinstall\").strip().lower()\n\nif CONTROLNET_INSTALL_MODE not in {\"reinstall\", \"update\", \"skip\"}:\n    raise ValueError(\"CONTROLNET_INSTALL_MODE must be one of: reinstall, update, skip\")\n\nprint(f\"ControlNet extension path: {CONTROLNET_DIR}\")\nprint(f\"Install mode: {CONTROLNET_INSTALL_MODE}\")\n\nif CONTROLNET_INSTALL_MODE == \"skip\":\n    print(\"ControlNet install skipped\")\nelse:\n    if os.path.isdir(CONTROLNET_DIR) and CONTROLNET_INSTALL_MODE == \"reinstall\":\n        print(\"Removing existing ControlNet directory...\")\n        shutil.rmtree(CONTROLNET_DIR)\n\n    if not os.path.isdir(CONTROLNET_DIR):\n        print(\"Cloning ControlNet repository...\")\n        subprocess.run([\"git\", \"clone\", CONTROLNET_REPO_URL, CONTROLNET_DIR], check=True)\n    else:\n        print(\"Updating ControlNet repository...\")\n        subprocess.run([\"git\", \"-C\", CONTROLNET_DIR, \"pull\", \"--ff-only\"], check=True)\n\nos.makedirs(CONTROLNET_MODELS_DIR, exist_ok=True)\nprint(\"ControlNet repository is ready\")\nprint(f\"ControlNet models directory: {CONTROLNET_MODELS_DIR}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-13T16:14:54.151538Z",
     "iopub.execute_input": "2026-02-13T16:14:54.152065Z",
     "iopub.status.idle": "2026-02-13T16:14:56.165417Z",
     "shell.execute_reply.started": "2026-02-13T16:14:54.152028Z",
     "shell.execute_reply": "2026-02-13T16:14:56.162520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ControlNet extension path: /kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet\nInstall mode: reinstall\nRemoving existing ControlNet directory...\nCloning ControlNet repository...\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Cloning into '/kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet'...\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "ControlNet repository is ready\nControlNet models directory: /kaggle/working/stable-diffusion-webui-forge/extensions/sd-webui-controlnet/models\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#ControlNET models download\n",
    "\n",
    "controlnet_models_to_download = [\n",
    "    (\"t2i-adapter_xl_openpose 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_openpose.safetensors\", \"t2i-adapter_xl_openpose.safetensors\", \"HF_TOKEN\"),\n",
    "    (\"t2i-adapter_xl_canny 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_canny.safetensors\", \"t2i-adapter_xl_canny.safetensors\", \"HF_TOKEN\"),\n",
    "    (\"t2i-adapter_xl_sketch 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_sketch.safetensors\", \"t2i-adapter_xl_sketch.safetensors\", \"HF_TOKEN\"),\n",
    "    (\"t2i-adapter_diffusers_xl_depth_midas 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"HF_TOKEN\"),\n",
    "    (\"t2i-adapter_diffusers_xl_depth_zoe 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"HF_TOKEN\"),\n",
    "    (\"t2i-adapter_diffusers_xl_lineart 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_lineart.safetensors\", \"t2i-adapter_diffusers_xl_lineart.safetensors\", \"HF_TOKEN\"),\n",
    "    #(\"\", \"\", \"\", \"\"),\n",
    "]\n",
    "\n",
    "print(f\"Total Models/checkpoints in the list: {len(controlnet_models_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "print(f\"All Models/checkpoints: {len(controlnet_models_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "for name, url, filename, source in controlnet_models_to_download:\n",
    "    output_path = os.path.join(CONTROLNET_MODELS_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(output_path) and os.path.getsize(output_path) > 1_000_000:\n",
    "        print(f\"  Already has → {name:<30} {filename}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    token = TOKENS.get(source)\n",
    "    \n",
    "    print(f\"  Loading {name:<30} ({source}) → {filename}\")\n",
    "    expected_mb = _estimate_expected_mb(name)\n",
    "    try:\n",
    "        download_file(url=url, output_path=output_path, token=token, expected_mb=expected_mb)\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n DONE. New: {len(controlnet_models_to_download) - skipped}, skipped: {skipped}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-13T16:15:02.576533Z",
     "iopub.execute_input": "2026-02-13T16:15:02.577067Z",
     "iopub.status.idle": "2026-02-13T16:15:12.615644Z",
     "shell.execute_reply.started": "2026-02-13T16:15:02.577033Z",
     "shell.execute_reply": "2026-02-13T16:15:12.614495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total Models/checkpoints in the list: 6\nAll Models/checkpoints: 6\n  Loading t2i-adapter_xl_openpose 151 MB (HF_TOKEN) → t2i-adapter_xl_openpose.safetensors\n  OK → t2i-adapter_xl_openpose.safetensors (aria2c)\n  Loading t2i-adapter_xl_canny 148 MB    (HF_TOKEN) → t2i-adapter_xl_canny.safetensors\n  OK → t2i-adapter_xl_canny.safetensors (aria2c)\n  Loading t2i-adapter_xl_sketch 148 MB   (HF_TOKEN) → t2i-adapter_xl_sketch.safetensors\n  OK → t2i-adapter_xl_sketch.safetensors (aria2c)\n  Loading t2i-adapter_diffusers_xl_depth_midas 151 MB (HF_TOKEN) → t2i-adapter_diffusers_xl_depth_midas.safetensors\n  OK → t2i-adapter_diffusers_xl_depth_midas.safetensors (aria2c)\n  Loading t2i-adapter_diffusers_xl_depth_zoe 151 MB (HF_TOKEN) → t2i-adapter_diffusers_xl_depth_zoe.safetensors\n  OK → t2i-adapter_diffusers_xl_depth_zoe.safetensors (aria2c)\n  Loading t2i-adapter_diffusers_xl_lineart 151 MB (HF_TOKEN) → t2i-adapter_diffusers_xl_lineart.safetensors\n  OK → t2i-adapter_diffusers_xl_lineart.safetensors (aria2c)\n\n DONE. New: 6, skipped: 0\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#controlnet models to download\n",
    "\n",
    "models_to_download = [\n",
    "    (\"WAI ILL V16.0 6,46 GB\", \"https://civitai.com/api/download/models/2514310?type=Model&format=SafeTensor&size=pruned&fp=fp16\", \"waiIllustriousSDXL_v160.safetensors\", \"CIVITAI\"),\n",
    "]\n",
    "\n",
    "print(f\"Total Models/checkpoints in the list: {len(models_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "print(f\"All Models/checkpoints: {len(models_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "for name, url, filename, source in models_to_download:\n",
    "    output_path = os.path.join(MODELS_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(output_path) and os.path.getsize(output_path) > 1_000_000:\n",
    "        print(f\"  Already has → {name:<30} {filename}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    token = TOKENS.get(source)\n",
    "    \n",
    "    print(f\"  Loading {name:<30} ({source}) → {filename}\")\n",
    "    expected_mb = _estimate_expected_mb(name)\n",
    "    try:\n",
    "        download_file(url=url, output_path=output_path, token=token, expected_mb=expected_mb)\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n DONE. New: {len(models_to_download) - skipped}, skipped: {skipped}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-13T16:15:17.345237Z",
     "iopub.execute_input": "2026-02-13T16:15:17.345728Z",
     "iopub.status.idle": "2026-02-13T16:16:49.957763Z",
     "shell.execute_reply.started": "2026-02-13T16:15:17.345698Z",
     "shell.execute_reply": "2026-02-13T16:16:49.956535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total Models/checkpoints in the list: 1\nAll Models/checkpoints: 1\n  Loading WAI ILL V16.0 6,46 GB          (CIVITAI) → waiIllustriousSDXL_v160.safetensors\n  OK → waiIllustriousSDXL_v160.safetensors (curl)\n\n DONE. New: 1, skipped: 0\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#LoRa\n",
    "\n",
    "lora_to_download = [\n",
    "    (\"Detailer IL V2 218 MB\",        \"https://civitai.com/api/download/models/1736373?type=Model&format=SafeTensor\",    \"detailer_v2_il.safetensors\",     \"CIVITAI\"),\n",
    "    (\"Realistic filter V1 55 MB\",    \"https://civitai.com/api/download/models/1124771?type=Model&format=SafeTensor\",    \"realistic_filter_v1_il.safetensors\", \"CIVITAI\"),\n",
    "    (\"Hyperrealistic V4 ILL 435 MB\", \"https://civitai.com/api/download/models/1914557?type=Model&format=SafeTensor\",    \"hyperrealistic_v4_ill.safetensors\",  \"CIVITAI\"),\n",
    "    (\"Niji semi realism V3.5 ILL 435 MB\", \"https://civitai.com/api/download/models/1882710?type=Model&format=SafeTensor\", \"niji_semi_realism_v35.safetensors\", \"CIVITAI\"), \n",
    "    (\"ATNR Style ILL V1.1 350 MB\", \"https://civitai.com/api/download/models/1711464?type=Model&format=SafeTensor\", \"atnr_style_ill_v1.1.safetensors\", \"CIVITAI\"), \n",
    "    (\"Face Enhancer Ill 218 MB\", \"https://civitai.com/api/download/models/1839268?type=Model&format=SafeTensor\", \"face_enhancer_ill.safetensors\", \"CIVITAI\"),\n",
    "    (\"Smooth Detailer Booster V4 243 MB\", \"https://civitai.com/api/download/models/2196453?type=Model&format=SafeTensor\", \"smooth_detailer_booster_v4.safetensors\", \"CIVITAI\"),\n",
    "    (\"USNR Style V-pred 157 MB\", \"https://civitai.com/api/download/models/2555444?type=Model&format=SafeTensor\", \"usnr_style_v_pred.safetensors\", \"CIVITAI\"),\n",
    "    (\"748cm Style V1 243 MB\", \"https://civitai.com/api/download/models/1056404?type=Model&format=SafeTensor\", \"748cm_style_v1.safetensors\", \"CIVITAI\"),\n",
    "    (\"Velvet's Mythic Fantasy Styles IL 218 MB\", \"https://civitai.com/api/download/models/2620790?type=Model&format=SafeTensor\", \"velvets_mythic_fantasy_styles_il.safetensors\", \"CIVITAI\"),\n",
    "    #(\"\", \"\", \"\", \"CIVITAI\"),\n",
    "]\n",
    "\n",
    "print(f\"Total LoRa in the list: {len(lora_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "print(f\"All LoRA: {len(lora_to_download)}\")\n",
    "skipped = 0\n",
    "\n",
    "for name, url, filename, source in lora_to_download:\n",
    "    output_path = os.path.join(LORA_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(output_path) and os.path.getsize(output_path) > 1_000_000:\n",
    "        print(f\"  Already has → {name:<30} {filename}\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    token = TOKENS.get(source)\n",
    "    \n",
    "    print(f\"  Loading {name:<30} ({source}) → {filename}\")\n",
    "    expected_mb = _estimate_expected_mb(name)\n",
    "    try:\n",
    "        download_file(url=url, output_path=output_path, token=token, expected_mb=expected_mb)\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "\n",
    "print(f\"\\n DONE. New: {len(lora_to_download) - skipped}, skipped: {skipped}\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-02-13T16:16:58.457746Z",
     "iopub.execute_input": "2026-02-13T16:16:58.458174Z",
     "iopub.status.idle": "2026-02-13T16:17:47.340359Z",
     "shell.execute_reply.started": "2026-02-13T16:16:58.458142Z",
     "shell.execute_reply": "2026-02-13T16:17:47.339104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total LoRa in the list: 10\nAll LoRA: 10\n  Loading Detailer IL V2 218 MB          (CIVITAI) → detailer_v2_il.safetensors\n  OK → detailer_v2_il.safetensors (curl)\n  Loading Realistic filter V1 55 MB      (CIVITAI) → realistic_filter_v1_il.safetensors\n  OK → realistic_filter_v1_il.safetensors (curl)\n  Loading Hyperrealistic V4 ILL 435 MB   (CIVITAI) → hyperrealistic_v4_ill.safetensors\n  OK → hyperrealistic_v4_ill.safetensors (curl)\n  Loading Niji semi realism V3.5 ILL 435 MB (CIVITAI) → niji_semi_realism_v35.safetensors\n  OK → niji_semi_realism_v35.safetensors (curl)\n  Loading ATNR Style ILL V1.1 350 MB     (CIVITAI) → atnr_style_ill_v1.1.safetensors\n  OK → atnr_style_ill_v1.1.safetensors (curl)\n  Loading Face Enhancer Ill 218 MB       (CIVITAI) → face_enhancer_ill.safetensors\n  OK → face_enhancer_ill.safetensors (curl)\n  Loading Smooth Detailer Booster V4 243 MB (CIVITAI) → smooth_detailer_booster_v4.safetensors\n  OK → smooth_detailer_booster_v4.safetensors (curl)\n  Loading USNR Style V-pred 157 MB       (CIVITAI) → usnr_style_v_pred.safetensors\n  OK → usnr_style_v_pred.safetensors (curl)\n  Loading 748cm Style V1 243 MB          (CIVITAI) → 748cm_style_v1.safetensors\n  OK → 748cm_style_v1.safetensors (curl)\n  Loading Velvet's Mythic Fantasy Styles IL 218 MB (CIVITAI) → velvets_mythic_fantasy_styles_il.safetensors\n  OK → velvets_mythic_fantasy_styles_il.safetensors (curl)\n\n DONE. New: 10, skipped: 0\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive outputs for download (folders like DD_MM_YYYY with PNG files)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "archive_source = OUTPUTS_DIR\n",
    "stamp = datetime.now().strftime(\"%d_%m_%Y_%H%M\")\n",
    "archive_base = os.path.join(BASE_DIR, f\"outputs_backup_{stamp}\")\n",
    "archive_zip = shutil.make_archive(archive_base, \"zip\", archive_source)\n",
    "\n",
    "size_mb = os.path.getsize(archive_zip) / (1024 * 1024)\n",
    "print(f\"Archive created: {archive_zip}\")\n",
    "print(f\"Archive size: {size_mb:.1f} MB\")\n",
    "\n",
    "if ON_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(archive_zip)\n",
    "    print(\"Download started via Colab files.download\")\n",
    "elif ON_KAGGLE:\n",
    "    print(\"Kaggle: open the Files panel and download this .zip manually.\")\n",
    "else:\n",
    "    print(\"Vast.ai/local: download the .zip from your workspace or Jupyter file browser.\")\n"
   ]
  }
 ]
}
