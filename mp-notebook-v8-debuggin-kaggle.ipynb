{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[{"file_id":"14sXDYyegbMQjRaEottMtnEr-SDILHZrW","timestamp":1771328894458}],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\nMAIN SETTINGS\n</div>","metadata":{"id":"8u27b0sPG4SA"}},{"cell_type":"code","source":"###SETTINGS###\n\nimport os\nimport re\nimport time\nimport subprocess\nimport shutil\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom getpass import getpass\nfrom urllib.parse import urlencode\n\n# Platform detection\nON_KAGGLE = os.path.exists('/kaggle')\nON_COLAB = 'COLAB_RELEASE_TAG' in os.environ or os.path.exists('/content')\nON_VAST = any(k in os.environ for k in (\"VAST_CONTAINERLABEL\", \"VAST_TCP_PORT_22\", \"CONTAINER_ID\")) or os.path.exists('/workspace')\n\n\nMAX_PARALLEL_DOWNLOADS = max(1, int(os.environ.get(\"MAX_PARALLEL_DOWNLOADS\", \"3\")))\nMIN_VALID_FILE_BYTES = int(os.environ.get(\"MIN_VALID_FILE_BYTES\", \"1000000\"))\n\nif shutil.which(\"aria2c\") is None:\n    print(\"aria2c not found → installing...\")\n    try:\n        subprocess.run([\"apt\", \"update\", \"-qq\"], check=True, capture_output=True)\n        result = subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", \"aria2\"], capture_output=True, text=True)\n        if result.returncode == 0:\n            print(\"aria2c installed successfully\")\n        else:\n            print(\"Install failed (code {}):\".format(result.returncode))\n            print(\"stderr:\", result.stderr.strip())\n    except subprocess.CalledProcessError as e:\n        print(f\"apt error (code {e.returncode}): {e.stderr}\")\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\nelse:\n    print(\"aria2c already available\")\n\n# Determining the working directory\npossible_bases = [\n    \"/workspace\",       # Vast.ai / RunPod\n    \"/kaggle/working\",  # Kaggle\n    \"/content\",         # Google Colab\n]\n\nBASE_DIR = None\nfor path in possible_bases:\n    if os.path.isdir(path):\n        BASE_DIR = path\n        break\n\nif BASE_DIR is None:\n    BASE_DIR = os.getcwd()\n    print(\"WARNING: Known directory not found:\", BASE_DIR)\n\nprint(\"Working directory:\", BASE_DIR)\n\n# Configuration\nFORGE_DIR        = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\")\nMODELS_DIR       = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Stable-diffusion\")\nLORA_DIR         = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Lora\")\nCONTROLNET_DIR   = os.path.join(FORGE_DIR, \"extensions\", \"sd-webui-controlnet\")\nCONTROLNET_MODELS_DIR = os.path.join(CONTROLNET_DIR, \"models\")\nEXTENSIONS_DIR   = os.path.join(FORGE_DIR, \"extensions\")\nOUTPUTS_DIR      = os.path.join(FORGE_DIR, \"outputs\")\nVOLUME_DIR       = os.path.join(BASE_DIR, \"volume\")\nGEN_DIR          = os.path.join(BASE_DIR, \"gen\")\n\nfor d in [MODELS_DIR, LORA_DIR, CONTROLNET_DIR, CONTROLNET_MODELS_DIR, EXTENSIONS_DIR, OUTPUTS_DIR, VOLUME_DIR, GEN_DIR]:\n    os.makedirs(d, exist_ok=True)\n\n# Dependencies used by generation cell\nfor pkg in [\"openpyxl\", \"requests\"]:\n    try:\n        __import__(pkg)\n    except Exception:\n        print(f\"Installing missing dependency: {pkg}\")\n        subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-q\", pkg], check=False)\n\n\ndef get_secret(name: str):\n    \"\"\"Get secret from env/Kaggle/Colab only.\"\"\"\n    value = os.environ.get(name)\n    if value:\n        return value.strip(), \"env\"\n\n    # Kaggle secrets\n    if ON_KAGGLE:\n        try:\n            from kaggle_secrets import UserSecretsClient\n            value = UserSecretsClient().get_secret(name)\n            if value:\n                return value.strip(), \"kaggle_secrets\"\n        except Exception:\n            pass\n\n    # Colab secrets panel: from google.colab import userdata\n    if ON_COLAB:\n        try:\n            from google.colab import userdata\n            value = userdata.get(name)\n            if value:\n                return value.strip(), \"colab_userdata\"\n        except Exception:\n            pass\n\n    return None, None\n\n\nCIVITAI_TOKEN, CIVITAI_SRC = get_secret(\"CIVITAI_TOKEN\")\nHF_TOKEN, HF_SRC = get_secret(\"HF_TOKEN\")\n\nif not CIVITAI_TOKEN:\n    manual_civitai = getpass(\"Enter CIVITAI_TOKEN (leave blank to skip): \").strip()\n    if manual_civitai:\n        CIVITAI_TOKEN, CIVITAI_SRC = manual_civitai, \"manual_input\"\n\nif not HF_TOKEN:\n    manual_hf = getpass(\"Enter HF_TOKEN (leave blank to skip): \").strip()\n    if manual_hf:\n        HF_TOKEN, HF_SRC = manual_hf, \"manual_input\"\n\nTOKENS = {}\nif CIVITAI_TOKEN:\n    TOKENS[\"CIVITAI\"] = CIVITAI_TOKEN\nif HF_TOKEN:\n    TOKENS[\"HF_TOKEN\"] = HF_TOKEN\n\nprint(\"Token sources:\")\nprint(f\"  CIVITAI_TOKEN: {CIVITAI_SRC or 'not found'}\")\nprint(f\"  HF_TOKEN: {HF_SRC or 'not found'}\")\nif ON_VAST:\n    print(\"Vast.ai tip: add CIVITAI_TOKEN/HF_TOKEN in template env vars, restart container, then rerun this cell.\")\n\nif not CIVITAI_TOKEN:\n    print(\"CivitAI token not found\")\nif not HF_TOKEN:\n    print(\"HF token not found\")\nif not TOKENS:\n    raise RuntimeError(\"No tokens were provided. Set secrets or enter at least one token (CivitAI or HF).\")\n\n\ndef _prepare_download_url(url, token):\n    \"\"\"CivitAI download works more reliably with token as query param.\"\"\"\n    if token and \"civitai.com/api/download/models\" in url and \"token=\" not in url:\n        sep = \"&\" if \"?\" in url else \"?\"\n        return f\"{url}{sep}{urlencode({'token': token})}\"\n    return url\n\n\ndef _looks_valid_file(path, min_bytes=MIN_VALID_FILE_BYTES):\n    return os.path.exists(path) and os.path.getsize(path) > min_bytes\n\n\ndef _human_mb(num_bytes):\n    return f\"{num_bytes / (1024 * 1024):.1f} MB\"\n\n\ndef _estimate_expected_mb(label):\n    # Examples: \"151 MB\", \"6,46 GB\"\n    match = re.search(r\"(\\d+[\\.,]?\\d*)\\s*(MB|GB)\", label, re.IGNORECASE)\n    if not match:\n        return None\n    value = float(match.group(1).replace(',', '.'))\n    unit = match.group(2).upper()\n    return value * (1024 if unit == \"GB\" else 1)\n\n\ndef _size_sanity_warning(path, expected_mb, tolerance=0.7):\n    if expected_mb is None or not os.path.exists(path):\n        return\n    actual_mb = os.path.getsize(path) / (1024 * 1024)\n    if actual_mb < expected_mb * tolerance:\n        print(f\"  WARNING: file size looks low ({actual_mb:.1f} MB vs expected ~{expected_mb:.1f} MB)\")\n\n\ndef _has_min_free_disk(path, required_mb, reserve_mb=1024):\n    if required_mb is None:\n        return True\n    usage = shutil.disk_usage(path)\n    free_mb = usage.free / (1024 * 1024)\n    return free_mb >= (required_mb + reserve_mb)\n\n\ndef _download_one(job, target_dir):\n    label, url, filename, token_name = job\n    token = TOKENS.get(token_name)\n    output_path = os.path.join(target_dir, filename)\n\n    expected_mb = _estimate_expected_mb(label)\n\n    if _looks_valid_file(output_path):\n        size = os.path.getsize(output_path)\n        print(f\"[SKIP] {label}: already exists ({_human_mb(size)})\")\n        _size_sanity_warning(output_path, expected_mb)\n        return (label, True, \"exists\")\n\n    if expected_mb is not None and not _has_min_free_disk(target_dir, expected_mb):\n        return (label, False, \"insufficient_disk\")\n\n    tmp_path = output_path + \".part\"\n    if os.path.exists(tmp_path):\n        os.remove(tmp_path)\n\n    final_url = _prepare_download_url(url, token if token_name == \"CIVITAI\" else None)\n\n    cmd = [\n        \"aria2c\",\n        \"--allow-overwrite=true\",\n        \"--auto-file-renaming=false\",\n        \"--continue=true\",\n        \"--max-connection-per-server=16\",\n        \"--split=16\",\n        \"--min-split-size=1M\",\n        \"--console-log-level=warn\",\n        \"--summary-interval=1\",\n        \"--check-certificate=false\",\n        \"--out\", os.path.basename(tmp_path),\n        \"--dir\", target_dir,\n        final_url,\n    ]\n\n    if token_name == \"HF_TOKEN\" and token:\n        cmd.insert(-1, f\"--header=Authorization: Bearer {token}\")\n\n    print(f\"[DOWNLOADING] {label}\")\n    result = subprocess.run(cmd, text=True, capture_output=True)\n    if result.returncode != 0:\n        stderr = (result.stderr or \"\").strip()\n        stdout = (result.stdout or \"\").strip()\n        msg = stderr or stdout or f\"aria2c exited {result.returncode}\"\n        if os.path.exists(tmp_path):\n            os.remove(tmp_path)\n        return (label, False, msg)\n\n    if not _looks_valid_file(tmp_path):\n        size = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0\n        if os.path.exists(tmp_path):\n            os.remove(tmp_path)\n        return (label, False, f\"downloaded file too small ({_human_mb(size)})\")\n\n    os.replace(tmp_path, output_path)\n    _size_sanity_warning(output_path, expected_mb)\n    return (label, True, _human_mb(os.path.getsize(output_path)))\n\n\ndef run_download_list(download_list, target_dir, title):\n    print(f\"\\n=== {title} ===\")\n    os.makedirs(target_dir, exist_ok=True)\n\n    if not download_list:\n        print(\"No items.\")\n        return\n\n    workers = min(MAX_PARALLEL_DOWNLOADS, len(download_list))\n    print(f\"Parallel downloads: {workers}\")\n\n    ok = 0\n    fail = 0\n\n    with ThreadPoolExecutor(max_workers=workers) as ex:\n        futures = [ex.submit(_download_one, job, target_dir) for job in download_list]\n        for fut in as_completed(futures):\n            label, success, info = fut.result()\n            if success:\n                ok += 1\n                print(f\"[OK]   {label} -> {info}\")\n            else:\n                fail += 1\n                print(f\"[FAIL] {label} -> {info}\")\n\n    print(f\"Done: OK={ok}, FAIL={fail}\")\n    if fail > 0:\n        raise RuntimeError(f\"Some downloads failed in {title}: {fail} item(s)\")\n\n\n","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"kTzG8SwHG4SC","executionInfo":{"status":"ok","timestamp":1771328411100,"user_tz":-120,"elapsed":18125,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"f393f94c-ad89-4ada-cf09-46ff7662971f","execution":{"iopub.status.busy":"2026-02-17T12:23:28.113106Z","iopub.execute_input":"2026-02-17T12:23:28.113608Z","iopub.status.idle":"2026-02-17T12:23:44.583904Z","shell.execute_reply.started":"2026-02-17T12:23:28.113574Z","shell.execute_reply":"2026-02-17T12:23:44.583205Z"}},"outputs":[{"name":"stdout","text":"aria2c not found → installing...\naria2c installed successfully\nWorking directory: /kaggle/working\nToken sources:\n  CIVITAI_TOKEN: kaggle_secrets\n  HF_TOKEN: kaggle_secrets\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"### OPTIONAL: KAGGLE/COLAB FORGE BOOTSTRAP ###\n\nimport os\nimport shutil\nimport subprocess\n\nif not (ON_KAGGLE or ON_COLAB):\n    print(\"Optional cell: предназначена только для Kaggle/Colab. Текущая платформа пропущена.\")\nelse:\n    required_packages = [\"git\", \"python3-venv\", \"python3-pip\"]\n    print(\"Checking/installing platform dependencies...\")\n    subprocess.run([\"apt\", \"update\", \"-qq\"], check=False)\n    subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", *required_packages], check=False)\n\n    launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n    git_head = os.path.join(FORGE_DIR, \".git\", \"HEAD\")\n    forge_ready = os.path.isfile(launch_script) and os.path.isfile(git_head)\n\n    if forge_ready:\n        print(\"WebUI Forge already exists and looks valid, skipping clone.\")\n    else:\n        if os.path.isdir(FORGE_DIR):\n            print(\"FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\")\n            shutil.rmtree(FORGE_DIR)\n\n        print(\"Cloning WebUI Forge...\")\n        subprocess.run([\n            \"git\", \"clone\", \"https://github.com/lllyasviel/stable-diffusion-webui-forge\", FORGE_DIR\n        ], check=True)\n\n        if not os.path.isfile(os.path.join(FORGE_DIR, \"webui.sh\")):\n            raise FileNotFoundError(\"Clone completed but webui.sh not found. Check repository state.\")\n\n    print(\"Optional bootstrap finished.\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wM3J4QA4G4SK","executionInfo":{"status":"ok","timestamp":1771328433337,"user_tz":-120,"elapsed":22233,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"6be9f00e-054b-4d09-a4c0-9c4486b602bd","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T12:23:44.585184Z","iopub.execute_input":"2026-02-17T12:23:44.585582Z","iopub.status.idle":"2026-02-17T12:24:09.542467Z","shell.execute_reply.started":"2026-02-17T12:23:44.585557Z","shell.execute_reply":"2026-02-17T12:24:09.541790Z"}},"outputs":[{"name":"stdout","text":"Checking/installing platform dependencies...\n","output_type":"stream"},{"name":"stderr","text":"\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n\n","output_type":"stream"},{"name":"stdout","text":"171 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","output_type":"stream"},{"name":"stderr","text":"W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n\n","output_type":"stream"},{"name":"stdout","text":"git is already the newest version (1:2.34.1-1ubuntu1.15).\nThe following additional packages will be installed:\n  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n  python3-pip-whl python3-pkg-resources python3-setuptools\n  python3-setuptools-whl python3-wheel python3.10 python3.10-dev\n  python3.10-minimal python3.10-venv\nSuggested packages:\n  python-setuptools-doc python3.10-doc binfmt-support\nThe following NEW packages will be installed:\n  python3-pip python3-pip-whl python3-setuptools python3-setuptools-whl\n  python3-venv python3-wheel python3.10-venv\nThe following packages will be upgraded:\n  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n  python3-pkg-resources python3.10 python3.10-dev python3.10-minimal\n8 upgraded, 7 newly installed, 0 to remove and 163 not upgraded.\nNeed to get 17.2 MB of archives.\nAfter this operation, 12.4 MB of additional disk space will be used.\n(Reading database ... 129147 files and directories currently installed.)\nPreparing to unpack .../00-python3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-dev (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../01-libpython3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../02-libpython3.10_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../03-python3.10_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../04-libpython3.10-stdlib_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../05-python3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-minimal (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../06-libpython3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.11) ...\nPreparing to unpack .../07-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\nSelecting previously unselected package python3-setuptools.\nPreparing to unpack .../08-python3-setuptools_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-setuptools (68.1.2-2~jammy3) ...\nSelecting previously unselected package python3-wheel.\nPreparing to unpack .../09-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\nUnpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\nSelecting previously unselected package python3-pip.\nPreparing to unpack .../10-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\nUnpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\nSelecting previously unselected package python3-pip-whl.\nPreparing to unpack .../11-python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\nUnpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\nSelecting previously unselected package python3-setuptools-whl.\nPreparing to unpack .../12-python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\nUnpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\nSelecting previously unselected package python3.10-venv.\nPreparing to unpack .../13-python3.10-venv_3.10.12-1~22.04.14_amd64.deb ...\nUnpacking python3.10-venv (3.10.12-1~22.04.14) ...\nSelecting previously unselected package python3-venv.\nPreparing to unpack .../14-python3-venv_3.10.6-1~22.04.1_amd64.deb ...\nUnpacking python3-venv (3.10.6-1~22.04.1) ...\nSetting up python3-pkg-resources (68.1.2-2~jammy3) ...\nSetting up python3-setuptools-whl (68.1.2-2~jammy3) ...\nSetting up python3-setuptools (68.1.2-2~jammy3) ...\nSetting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\nSetting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\nSetting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\nSetting up python3.10-minimal (3.10.12-1~22.04.14) ...\nSetting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) ...\nSetting up libpython3.10:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3.10 (3.10.12-1~22.04.14) ...\nSetting up libpython3.10-dev:amd64 (3.10.12-1~22.04.14) ...\nSetting up python3.10-dev (3.10.12-1~22.04.14) ...\nSetting up python3.10-venv (3.10.12-1~22.04.14) ...\nSetting up python3-venv (3.10.6-1~22.04.1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\nFORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\nCloning WebUI Forge...\n","output_type":"stream"},{"name":"stderr","text":"Cloning into '/kaggle/working/stable-diffusion-webui-forge'...\n","output_type":"stream"},{"name":"stdout","text":"Optional bootstrap finished.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"### RUN WEBUI (PURE PYTHON) ###\n\nimport os\nimport subprocess\nfrom pathlib import Path\n\nforge_dir = Path(FORGE_DIR)\nif not forge_dir.exists():\n    raise FileNotFoundError(f\"FORGE_DIR не найден: {forge_dir}\")\n\nlaunch_utils_path = forge_dir / \"modules\" / \"launch_utils.py\"\nif launch_utils_path.exists():\n    content = launch_utils_path.read_text(encoding=\"utf-8\")\n    old = 'run_pip(f\"install {clip_package}\", \"clip\")'\n    new = 'run_pip(f\"install --no-build-isolation {clip_package}\", \"clip\")'\n    if old in content and new not in content:\n        launch_utils_path.write_text(content.replace(old, new), encoding=\"utf-8\")\n        print(\"Patched CLIP install command (removed unsupported --no-use-pep517 flag).\")\n    else:\n        print(\"CLIP install patch already applied or not required.\")\nelse:\n    print(f\"Warning: {launch_utils_path} not found, skipping CLIP patch.\")\n\ncmd = [\"bash\", \"webui.sh\", \"-f\", \"--xformers\", \"--api\", \"--port\", \"17860\"]\nprint(\"Running:\", \" \".join(cmd), \"in\", forge_dir)\nsubprocess.run(cmd, cwd=forge_dir, check=True)\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpZBUyZoYFHL","executionInfo":{"status":"ok","timestamp":1771328692825,"user_tz":-120,"elapsed":188283,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"9fa9759a-2652-4c2e-d911-73a85dcf233c","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T12:24:09.543294Z","iopub.execute_input":"2026-02-17T12:24:09.543492Z","execution_failed":"2026-02-17T12:26:41.803Z"}},"outputs":[{"name":"stdout","text":"Patched CLIP install command (removed unsupported --no-use-pep517 flag).\nRunning: bash webui.sh -f --xformers --api --port 17860 in /kaggle/working/stable-diffusion-webui-forge\n\n################################################################\n\u001b[1m\u001b[32mInstall script for stable-diffusion + Web UI\n\u001b[1m\u001b[34mTested on Debian 11 (Bullseye), Fedora 34+ and openSUSE Leap 15.4 or newer.\u001b[0m\n################################################################\n\n################################################################\nRunning on \u001b[1m\u001b[32mroot\u001b[0m user\n################################################################\n\n################################################################\nRepo already cloned, using it as install directory\n################################################################\n\n################################################################\nCreate and activate python venv\n################################################################\nRequirement already satisfied: pip in ./venv/lib/python3.10/site-packages (22.0.2)\nCollecting pip\n  Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 11.6 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 22.0.2\n    Uninstalling pip-22.0.2:\n      Successfully uninstalled pip-22.0.2\nSuccessfully installed pip-26.0.1\n\n################################################################\nLaunching launch.py...\n################################################################\nglibc version is 2.35\nCheck TCMalloc: libtcmalloc_minimal.so.4\nlibtcmalloc_minimal.so.4 is linked with libc.so,execute LD_PRELOAD=/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\nPython 3.10.12 (main, Jan 26 2026, 14:55:28) [GCC 11.4.0]\nVersion: f2.0.1v1.10.1-previous-669-gdfdcbab6\nCommit hash: dfdcbab685e57677014f05a3309b48cc87383167\nInstalling torch and torchvision\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.0/781.0 MB 52.5 MB/s  0:00:06\nCollecting torchvision==0.18.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 20.4 MB/s  0:00:00\nCollecting filelock (from torch==2.3.1)\n  Downloading filelock-3.24.2-py3-none-any.whl.metadata (2.0 kB)\nCollecting typing-extensions>=4.8.0 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting sympy (from torch==2.3.1)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting networkx (from torch==2.3.1)\n  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting jinja2 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting fsspec (from torch==2.3.1)\n  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 158.1 MB/s  0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 39.5 MB/s  0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 140.8 MB/s  0:00:00\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 55.0 MB/s  0:00:06\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 83.3 MB/s  0:00:03\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 103.8 MB/s  0:00:01\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 133.8 MB/s  0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 124.5 MB/s  0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 125.2 MB/s  0:00:01\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 126.6 MB/s  0:00:01\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nCollecting triton==2.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.1/168.1 MB 83.4 MB/s  0:00:02\nCollecting numpy (from torchvision==0.18.1)\n  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.18.1)\n  Downloading pillow-12.1.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch==2.3.1)\n  Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.1)\n  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nDownloading pillow-12.1.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 6.3 MB/s  0:00:01\nDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nDownloading filelock-3.24.2-py3-none-any.whl (24 kB)\nDownloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\nDownloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\nDownloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\nDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 73.7 MB/s  0:00:00\nDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 131.7 MB/s  0:00:00\nDownloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 149.7 MB/s  0:00:00\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 135.9 MB/s  0:00:00\nDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 19.3 MB/s  0:00:00\nInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n\nSuccessfully installed MarkupSafe-3.0.3 filelock-3.24.2 fsspec-2026.2.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-12.1.1 sympy-1.14.0 torch-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1 typing-extensions-4.15.0\nInstalling clip\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/kaggle/working/stable-diffusion-webui-forge/launch.py\", line 54, in <module>\n    main()\n  File \"/kaggle/working/stable-diffusion-webui-forge/launch.py\", line 42, in main\n    prepare_environment()\n  File \"/kaggle/working/stable-diffusion-webui-forge/modules/launch_utils.py\", line 443, in prepare_environment\n    run_pip(f\"install --no-build-isolation {clip_package}\", \"clip\")\n  File \"/kaggle/working/stable-diffusion-webui-forge/modules/launch_utils.py\", line 153, in run_pip\n    return run(f'\"{python}\" -m pip {command} --prefer-binary{index_url_line}', desc=f\"Installing {desc}\", errdesc=f\"Couldn't install {desc}\", live=live)\n  File \"/kaggle/working/stable-diffusion-webui-forge/modules/launch_utils.py\", line 125, in run\n    raise RuntimeError(\"\\n\".join(error_bits))\nRuntimeError: Couldn't install clip.\nCommand: \"/kaggle/working/stable-diffusion-webui-forge/venv/bin/python\" -m pip install --no-build-isolation --no-use-pep517 https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip --prefer-binary\nError code: 2\nstderr: \n[optparse.groups]Usage:[/]   \n  /kaggle/working/stable-diffusion-webui-forge/venv/bin/python -m pip install \\[options] <requirement specifier> \\[package-index-options] ...\n  /kaggle/working/stable-diffusion-webui-forge/venv/bin/python -m pip install \\[options] -r <requirements file> \\[package-index-options] ...\n  /kaggle/working/stable-diffusion-webui-forge/venv/bin/python -m pip install \\[options] [-e] <vcs project url> ...\n  /kaggle/working/stable-diffusion-webui-forge/venv/bin/python -m pip install \\[options] [-e] <local project path> ...\n  /kaggle/working/stable-diffusion-webui-forge/venv/bin/python -m pip install \\[options] <archive url/path> ...\n\nno such option: --no-use-pep517\n\n","output_type":"stream"}],"execution_count":null}]}
