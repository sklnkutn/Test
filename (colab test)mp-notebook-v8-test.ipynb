{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[{"file_id":"14sXDYyegbMQjRaEottMtnEr-SDILHZrW","timestamp":1771324551202}],"gpuType":"T4"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\n","MAIN SETTINGS\n","</div>"],"metadata":{"id":"8u27b0sPG4SA"}},{"cell_type":"code","source":["###SETTINGS###\n","\n","import os\n","import re\n","import time\n","import subprocess\n","import shutil\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from getpass import getpass\n","from urllib.parse import urlencode\n","\n","# Platform detection\n","ON_KAGGLE = os.path.exists('/kaggle')\n","ON_COLAB = 'COLAB_RELEASE_TAG' in os.environ or os.path.exists('/content')\n","ON_VAST = any(k in os.environ for k in (\"VAST_CONTAINERLABEL\", \"VAST_TCP_PORT_22\", \"CONTAINER_ID\")) or os.path.exists('/workspace')\n","\n","\n","MAX_PARALLEL_DOWNLOADS = max(1, int(os.environ.get(\"MAX_PARALLEL_DOWNLOADS\", \"3\")))\n","MIN_VALID_FILE_BYTES = int(os.environ.get(\"MIN_VALID_FILE_BYTES\", \"1000000\"))\n","\n","if shutil.which(\"aria2c\") is None:\n","    print(\"aria2c not found → installing...\")\n","    try:\n","        subprocess.run([\"apt\", \"update\", \"-qq\"], check=True, capture_output=True)\n","        result = subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", \"aria2\"], capture_output=True, text=True)\n","        if result.returncode == 0:\n","            print(\"aria2c installed successfully\")\n","        else:\n","            print(\"Install failed (code {}):\".format(result.returncode))\n","            print(\"stderr:\", result.stderr.strip())\n","    except subprocess.CalledProcessError as e:\n","        print(f\"apt error (code {e.returncode}): {e.stderr}\")\n","    except Exception as e:\n","        print(f\"Unexpected error: {e}\")\n","else:\n","    print(\"aria2c already available\")\n","\n","# Determining the working directory\n","possible_bases = [\n","    \"/workspace\",       # Vast.ai / RunPod\n","    \"/kaggle/working\",  # Kaggle\n","    \"/content\",         # Google Colab\n","]\n","\n","BASE_DIR = None\n","for path in possible_bases:\n","    if os.path.isdir(path):\n","        BASE_DIR = path\n","        break\n","\n","if BASE_DIR is None:\n","    BASE_DIR = os.getcwd()\n","    print(\"WARNING: Known directory not found:\", BASE_DIR)\n","\n","print(\"Working directory:\", BASE_DIR)\n","\n","# Configuration\n","FORGE_DIR        = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\")\n","MODELS_DIR       = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Stable-diffusion\")\n","LORA_DIR         = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Lora\")\n","CONTROLNET_DIR   = os.path.join(FORGE_DIR, \"extensions\", \"sd-webui-controlnet\")\n","CONTROLNET_MODELS_DIR = os.path.join(CONTROLNET_DIR, \"models\")\n","EXTENSIONS_DIR   = os.path.join(FORGE_DIR, \"extensions\")\n","OUTPUTS_DIR      = os.path.join(FORGE_DIR, \"outputs\")\n","VOLUME_DIR       = os.path.join(BASE_DIR, \"volume\")\n","GEN_DIR          = os.path.join(BASE_DIR, \"gen\")\n","\n","for d in [MODELS_DIR, LORA_DIR, CONTROLNET_DIR, CONTROLNET_MODELS_DIR, EXTENSIONS_DIR, OUTPUTS_DIR, VOLUME_DIR, GEN_DIR]:\n","    os.makedirs(d, exist_ok=True)\n","\n","# Dependencies used by generation cell\n","for pkg in [\"openpyxl\", \"requests\"]:\n","    try:\n","        __import__(pkg)\n","    except Exception:\n","        print(f\"Installing missing dependency: {pkg}\")\n","        subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-q\", pkg], check=False)\n","\n","\n","def get_secret(name: str):\n","    \"\"\"Get secret from env/Kaggle/Colab only.\"\"\"\n","    value = os.environ.get(name)\n","    if value:\n","        return value.strip(), \"env\"\n","\n","    # Kaggle secrets\n","    if ON_KAGGLE:\n","        try:\n","            from kaggle_secrets import UserSecretsClient\n","            value = UserSecretsClient().get_secret(name)\n","            if value:\n","                return value.strip(), \"kaggle_secrets\"\n","        except Exception:\n","            pass\n","\n","    # Colab secrets panel: from google.colab import userdata\n","    if ON_COLAB:\n","        try:\n","            from google.colab import userdata\n","            value = userdata.get(name)\n","            if value:\n","                return value.strip(), \"colab_userdata\"\n","        except Exception:\n","            pass\n","\n","    return None, None\n","\n","\n","CIVITAI_TOKEN, CIVITAI_SRC = get_secret(\"CIVITAI_TOKEN\")\n","HF_TOKEN, HF_SRC = get_secret(\"HF_TOKEN\")\n","\n","if not CIVITAI_TOKEN:\n","    manual_civitai = getpass(\"Enter CIVITAI_TOKEN (leave blank to skip): \").strip()\n","    if manual_civitai:\n","        CIVITAI_TOKEN, CIVITAI_SRC = manual_civitai, \"manual_input\"\n","\n","if not HF_TOKEN:\n","    manual_hf = getpass(\"Enter HF_TOKEN (leave blank to skip): \").strip()\n","    if manual_hf:\n","        HF_TOKEN, HF_SRC = manual_hf, \"manual_input\"\n","\n","TOKENS = {}\n","if CIVITAI_TOKEN:\n","    TOKENS[\"CIVITAI\"] = CIVITAI_TOKEN\n","if HF_TOKEN:\n","    TOKENS[\"HF_TOKEN\"] = HF_TOKEN\n","\n","print(\"Token sources:\")\n","print(f\"  CIVITAI_TOKEN: {CIVITAI_SRC or 'not found'}\")\n","print(f\"  HF_TOKEN: {HF_SRC or 'not found'}\")\n","if ON_VAST:\n","    print(\"Vast.ai tip: add CIVITAI_TOKEN/HF_TOKEN in template env vars, restart container, then rerun this cell.\")\n","\n","if not CIVITAI_TOKEN:\n","    print(\"CivitAI token not found\")\n","if not HF_TOKEN:\n","    print(\"HF token not found\")\n","if not TOKENS:\n","    raise RuntimeError(\"No tokens were provided. Set secrets or enter at least one token (CivitAI or HF).\")\n","\n","\n","def _prepare_download_url(url, token):\n","    \"\"\"CivitAI download works more reliably with token as query param.\"\"\"\n","    if token and \"civitai.com/api/download/models\" in url and \"token=\" not in url:\n","        sep = \"&\" if \"?\" in url else \"?\"\n","        return f\"{url}{sep}{urlencode({'token': token})}\"\n","    return url\n","\n","\n","def _looks_valid_file(path, min_bytes=MIN_VALID_FILE_BYTES):\n","    return os.path.exists(path) and os.path.getsize(path) > min_bytes\n","\n","\n","def _human_mb(num_bytes):\n","    return f\"{num_bytes / (1024 * 1024):.1f} MB\"\n","\n","\n","def _estimate_expected_mb(label):\n","    # Examples: \"151 MB\", \"6,46 GB\"\n","    match = re.search(r\"(\\d+[\\.,]?\\d*)\\s*(MB|GB)\", label, re.IGNORECASE)\n","    if not match:\n","        return None\n","    value = float(match.group(1).replace(',', '.'))\n","    unit = match.group(2).upper()\n","    return value * (1024 if unit == \"GB\" else 1)\n","\n","\n","def _size_sanity_warning(path, expected_mb, tolerance=0.7):\n","    if expected_mb is None or not os.path.exists(path):\n","        return\n","    actual_mb = os.path.getsize(path) / (1024 * 1024)\n","    if actual_mb < expected_mb * tolerance:\n","        print(f\"  WARNING: file size looks low ({actual_mb:.1f} MB vs expected ~{expected_mb:.1f} MB)\")\n","\n","\n","def _has_min_free_disk(path, required_mb, reserve_mb=1024):\n","    if required_mb is None:\n","        return True\n","    usage = shutil.disk_usage(path)\n","    free_mb = usage.free / (1024 * 1024)\n","    return free_mb >= (required_mb + reserve_mb)\n","\n","\n","def _download_one(job, target_dir):\n","    label, url, filename, token_name = job\n","    token = TOKENS.get(token_name)\n","    output_path = os.path.join(target_dir, filename)\n","\n","    expected_mb = _estimate_expected_mb(label)\n","\n","    if _looks_valid_file(output_path):\n","        size = os.path.getsize(output_path)\n","        print(f\"[SKIP] {label}: already exists ({_human_mb(size)})\")\n","        _size_sanity_warning(output_path, expected_mb)\n","        return (label, True, \"exists\")\n","\n","    if expected_mb is not None and not _has_min_free_disk(target_dir, expected_mb):\n","        return (label, False, \"insufficient_disk\")\n","\n","    tmp_path = output_path + \".part\"\n","    if os.path.exists(tmp_path):\n","        os.remove(tmp_path)\n","\n","    final_url = _prepare_download_url(url, token if token_name == \"CIVITAI\" else None)\n","\n","    cmd = [\n","        \"aria2c\",\n","        \"--allow-overwrite=true\",\n","        \"--auto-file-renaming=false\",\n","        \"--continue=true\",\n","        \"--max-connection-per-server=16\",\n","        \"--split=16\",\n","        \"--min-split-size=1M\",\n","        \"--console-log-level=warn\",\n","        \"--summary-interval=1\",\n","        \"--check-certificate=false\",\n","        \"--out\", os.path.basename(tmp_path),\n","        \"--dir\", target_dir,\n","        final_url,\n","    ]\n","\n","    if token_name == \"HF_TOKEN\" and token:\n","        cmd.insert(-1, f\"--header=Authorization: Bearer {token}\")\n","\n","    print(f\"[DOWNLOADING] {label}\")\n","    result = subprocess.run(cmd, text=True, capture_output=True)\n","    if result.returncode != 0:\n","        stderr = (result.stderr or \"\").strip()\n","        stdout = (result.stdout or \"\").strip()\n","        msg = stderr or stdout or f\"aria2c exited {result.returncode}\"\n","        if os.path.exists(tmp_path):\n","            os.remove(tmp_path)\n","        return (label, False, msg)\n","\n","    if not _looks_valid_file(tmp_path):\n","        size = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0\n","        if os.path.exists(tmp_path):\n","            os.remove(tmp_path)\n","        return (label, False, f\"downloaded file too small ({_human_mb(size)})\")\n","\n","    os.replace(tmp_path, output_path)\n","    _size_sanity_warning(output_path, expected_mb)\n","    return (label, True, _human_mb(os.path.getsize(output_path)))\n","\n","\n","def run_download_list(download_list, target_dir, title):\n","    print(f\"\\n=== {title} ===\")\n","    os.makedirs(target_dir, exist_ok=True)\n","\n","    if not download_list:\n","        print(\"No items.\")\n","        return\n","\n","    workers = min(MAX_PARALLEL_DOWNLOADS, len(download_list))\n","    print(f\"Parallel downloads: {workers}\")\n","\n","    ok = 0\n","    fail = 0\n","\n","    with ThreadPoolExecutor(max_workers=workers) as ex:\n","        futures = [ex.submit(_download_one, job, target_dir) for job in download_list]\n","        for fut in as_completed(futures):\n","            label, success, info = fut.result()\n","            if success:\n","                ok += 1\n","                print(f\"[OK]   {label} -> {info}\")\n","            else:\n","                fail += 1\n","                print(f\"[FAIL] {label} -> {info}\")\n","\n","    print(f\"Done: OK={ok}, FAIL={fail}\")\n","    if fail > 0:\n","        raise RuntimeError(f\"Some downloads failed in {title}: {fail} item(s)\")\n","\n","\n"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"kTzG8SwHG4SC","executionInfo":{"status":"ok","timestamp":1771323549731,"user_tz":-120,"elapsed":21682,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"526aa1ea-b954-47db-9b57-4cf9941170b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["aria2c not found → installing...\n","aria2c installed successfully\n","Working directory: /content\n","Token sources:\n","  CIVITAI_TOKEN: colab_userdata\n","  HF_TOKEN: colab_userdata\n"]}],"execution_count":1},{"cell_type":"markdown","source":["<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\n","DOWNLOAD BLOCK\n","</div>"],"metadata":{"id":"Iq-cxkqWG4SG"}},{"cell_type":"code","source":["### CONTROLNET INSTALL OPTIONS ###\n","\n","# Option A (default): force clean reinstall\n","# Option B: set CONTROLNET_INSTALL_MODE = \"update\" for git pull in existing repo\n","# Option C: set CONTROLNET_INSTALL_MODE = \"skip\" to keep current state\n","\n","CONTROLNET_REPO_URL = \"https://github.com/Mikubill/sd-webui-controlnet\"\n","CONTROLNET_INSTALL_MODE = os.environ.get(\"CONTROLNET_INSTALL_MODE\", \"reinstall\").strip().lower()\n","\n","if CONTROLNET_INSTALL_MODE not in {\"reinstall\", \"update\", \"skip\"}:\n","    raise ValueError(\"CONTROLNET_INSTALL_MODE must be one of: reinstall, update, skip\")\n","\n","print(f\"ControlNet extension path: {CONTROLNET_DIR}\")\n","print(f\"Install mode: {CONTROLNET_INSTALL_MODE}\")\n","\n","if CONTROLNET_INSTALL_MODE == \"skip\":\n","    print(\"ControlNet install skipped\")\n","else:\n","    if os.path.isdir(CONTROLNET_DIR) and CONTROLNET_INSTALL_MODE == \"reinstall\":\n","        print(\"Removing existing ControlNet directory...\")\n","        shutil.rmtree(CONTROLNET_DIR)\n","\n","    if not os.path.isdir(CONTROLNET_DIR):\n","        print(\"Cloning ControlNet repository...\")\n","        subprocess.run([\"git\", \"clone\", CONTROLNET_REPO_URL, CONTROLNET_DIR], check=True)\n","    else:\n","        print(\"Updating ControlNet repository...\")\n","        subprocess.run([\"git\", \"-C\", CONTROLNET_DIR, \"pull\", \"--ff-only\"], check=True)\n","\n","os.makedirs(CONTROLNET_MODELS_DIR, exist_ok=True)\n","print(\"ControlNet repository is ready\")\n","print(f\"ControlNet models directory: {CONTROLNET_MODELS_DIR}\")\n","\n","#ControlNET models download\n","\n","controlnet_models_to_download = [\n","    (\"t2i-adapter_xl_openpose 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_openpose.safetensors\", \"t2i-adapter_xl_openpose.safetensors\", \"HF_TOKEN\"),\n","    (\"t2i-adapter_xl_canny 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_canny.safetensors\", \"t2i-adapter_xl_canny.safetensors\", \"HF_TOKEN\"),\n","    (\"t2i-adapter_xl_sketch 148 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_xl_sketch.safetensors\", \"t2i-adapter_xl_sketch.safetensors\", \"HF_TOKEN\"),\n","    (\"t2i-adapter_diffusers_xl_depth_midas 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"t2i-adapter_diffusers_xl_depth_midas.safetensors\", \"HF_TOKEN\"),\n","    (\"t2i-adapter_diffusers_xl_depth_zoe 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"t2i-adapter_diffusers_xl_depth_zoe.safetensors\", \"HF_TOKEN\"),\n","    (\"t2i-adapter_diffusers_xl_lineart 151 MB\", \"https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/t2i-adapter_diffusers_xl_lineart.safetensors\", \"t2i-adapter_diffusers_xl_lineart.safetensors\", \"HF_TOKEN\"),\n","]\n","\n","run_download_list(controlnet_models_to_download, CONTROLNET_MODELS_DIR, \"ControlNet\")\n","\n","#Checkpoints download\n","\n","models_to_download = [\n","    (\"WAI ILL V16.0 6,46 GB\", \"https://civitai.com/api/download/models/2514310?type=Model&format=SafeTensor&size=pruned&fp=fp16\", \"wai_v160.safetensors\", \"CIVITAI\"),\n","]\n","\n","run_download_list(models_to_download, MODELS_DIR, \"Checkpoints\")\n","\n","#LoRa download\n","\n","lora_to_download = [\n","    (\"Detailer IL V2 218 MB\",        \"https://civitai.com/api/download/models/1736373?type=Model&format=SafeTensor\",    \"detailer_v2_il.safetensors\",     \"CIVITAI\"),\n","    (\"Realistic filter V1 55 MB\",    \"https://civitai.com/api/download/models/1124771?type=Model&format=SafeTensor\",    \"realistic_filter_v1_il.safetensors\", \"CIVITAI\"),\n","    (\"Hyperrealistic V4 ILL 435 MB\", \"https://civitai.com/api/download/models/1914557?type=Model&format=SafeTensor\",    \"hyperrealistic_v4_ill.safetensors\",  \"CIVITAI\"),\n","    (\"Niji semi realism V3.5 ILL 435 MB\", \"https://civitai.com/api/download/models/1882710?type=Model&format=SafeTensor\", \"niji_v35.safetensors\", \"CIVITAI\"),\n","    (\"ATNR Style ILL V1.1 350 MB\", \"https://civitai.com/api/download/models/1711464?type=Model&format=SafeTensor\", \"atnr_style_ill_v1.1.safetensors\", \"CIVITAI\"),\n","    (\"Face Enhancer Ill 218 MB\", \"https://civitai.com/api/download/models/1839268?type=Model&format=SafeTensor\", \"face_enhancer_ill.safetensors\", \"CIVITAI\"),\n","    (\"Smooth Detailer Booster V4 243 MB\", \"https://civitai.com/api/download/models/2196453?type=Model&format=SafeTensor\", \"smooth_detailer_booster_v4.safetensors\", \"CIVITAI\"),\n","    (\"USNR Style V-pred 157 MB\", \"https://civitai.com/api/download/models/2555444?type=Model&format=SafeTensor\", \"usnr_style.safetensors\", \"CIVITAI\"),\n","    (\"748cm Style V1 243 MB\", \"https://civitai.com/api/download/models/1056404?type=Model&format=SafeTensor\", \"748cm_style_v1.safetensors\", \"CIVITAI\"),\n","    (\"Velvet's Mythic Fantasy Styles IL 218 MB\", \"https://civitai.com/api/download/models/2620790?type=Model&format=SafeTensor\", \"velvets_styles.safetensors\", \"CIVITAI\"),\n","    (\"Pixel Art Style IL V7 435 MB\", \"https://civitai.com/api/download/models/2661972?type=Model&format=SafeTensor\", \"pixel_art.safetensors\", \"CIVITAI\"),\n","]\n","\n","run_download_list(lora_to_download, LORA_DIR, \"LoRA\")\n","\n"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"Xs_MoAfJG4SH","executionInfo":{"status":"ok","timestamp":1771323660846,"user_tz":-120,"elapsed":65668,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"8bfd94da-90af-4757-dcaf-610bcf732a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["ControlNet extension path: /content/stable-diffusion-webui-forge/extensions/sd-webui-controlnet\n","Install mode: reinstall\n","Cloning ControlNet repository...\n","ControlNet repository is ready\n","ControlNet models directory: /content/stable-diffusion-webui-forge/extensions/sd-webui-controlnet/models\n","\n","=== ControlNet ===\n","Parallel downloads: 3\n","[DOWNLOADING] t2i-adapter_xl_openpose 151 MB\n","[DOWNLOADING] t2i-adapter_xl_canny 148 MB\n","[DOWNLOADING] t2i-adapter_xl_sketch 148 MB\n","[DOWNLOADING] t2i-adapter_diffusers_xl_depth_midas 151 MB[OK]   t2i-adapter_xl_sketch 148 MB -> 147.9 MB\n","\n","[DOWNLOADING] t2i-adapter_diffusers_xl_depth_zoe 151 MB\n","[OK]   t2i-adapter_xl_canny 148 MB -> 147.9 MB\n","[DOWNLOADING] t2i-adapter_diffusers_xl_lineart 151 MB[OK]   t2i-adapter_xl_openpose 151 MB -> 150.7 MB\n","\n","[OK]   t2i-adapter_diffusers_xl_depth_midas 151 MB -> 150.7 MB\n","[OK]   t2i-adapter_diffusers_xl_depth_zoe 151 MB -> 150.7 MB\n","[OK]   t2i-adapter_diffusers_xl_lineart 151 MB -> 150.7 MB\n","Done: OK=6, FAIL=0\n","\n","=== Checkpoints ===\n","Parallel downloads: 1\n","[DOWNLOADING] WAI ILL V16.0 6,46 GB\n","[OK]   WAI ILL V16.0 6,46 GB -> 6616.6 MB\n","Done: OK=1, FAIL=0\n","\n","=== LoRA ===\n","Parallel downloads: 3\n","[DOWNLOADING] Detailer IL V2 218 MB\n","[DOWNLOADING] Hyperrealistic V4 ILL 435 MB\n","[DOWNLOADING] Realistic filter V1 55 MB\n","[DOWNLOADING] Niji semi realism V3.5 ILL 435 MB\n","[OK]   Realistic filter V1 55 MB -> 54.8 MB\n","[DOWNLOADING] ATNR Style ILL V1.1 350 MB\n","[OK]   Hyperrealistic V4 ILL 435 MB -> 435.4 MB\n","[OK]   ATNR Style ILL V1.1 350 MB -> 350.2 MB[DOWNLOADING] Face Enhancer Ill 218 MB\n","[DOWNLOADING] Smooth Detailer Booster V4 243 MB\n","\n","[OK]   Niji semi realism V3.5 ILL 435 MB -> 435.4 MB\n","[OK]   Smooth Detailer Booster V4 243 MB -> 243.2 MB[DOWNLOADING] USNR Style V-pred 157 MB\n","\n","[OK]   Face Enhancer Ill 218 MB -> 217.9 MB\n","[DOWNLOADING] 748cm Style V1 243 MB\n","[DOWNLOADING] Velvet's Mythic Fantasy Styles IL 218 MB[OK]   USNR Style V-pred 157 MB -> 156.9 MB\n","\n","[OK]   748cm Style V1 243 MB -> 243.2 MB\n","[DOWNLOADING] Pixel Art Style IL V7 435 MB\n","[OK]   Detailer IL V2 218 MB -> 217.9 MB\n","  WARNING: file size looks low (217.9 MB vs expected ~435.0 MB)\n","[OK]   Pixel Art Style IL V7 435 MB -> 217.9 MB\n","[OK]   Velvet's Mythic Fantasy Styles IL 218 MB -> 217.9 MB\n","Done: OK=11, FAIL=0\n"]}],"execution_count":3},{"cell_type":"markdown","source":["<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\n","ARCHIVE+OUTPUT\n","</div>"],"metadata":{"id":"RMdZZv6XG4SI"}},{"cell_type":"code","source":["### API GENERATION FROM XLSX ###\n","\n","import os\n","import re\n","import json\n","import glob\n","import time\n","import shutil\n","import zipfile\n","import base64\n","from datetime import datetime\n","\n","import requests\n","from openpyxl import load_workbook\n","\n","API_BASE = os.environ.get(\"FORGE_API_BASE\", \"http://127.0.0.1:17860\")\n","TXT2IMG_URL = f\"{API_BASE}/sdapi/v1/txt2img\"\n","OPENAPI_URL = f\"{API_BASE}/openapi.json\"\n","\n","PROMPTS_CANDIDATES = [\n","    os.path.join(GEN_DIR, \"prompts.xlsx\"),\n","    os.path.join(GEN_DIR, \"prompts.xlxs\"),\n","    os.path.join(GEN_DIR, \"Prompts.xlsx\"),\n","    os.path.join(GEN_DIR, \"Prompts.xlxs\"),\n","    os.path.join(BASE_DIR, \"prompts.xlsx\"),\n","    os.path.join(BASE_DIR, \"prompts.xlxs\"),\n","    os.path.join(BASE_DIR, \"Prompts.xlsx\"),\n","    os.path.join(BASE_DIR, \"Prompts.xlxs\"),\n","    \"/workspace/gen/prompts.xlsx\",\n","    \"/workspace/gen/prompts.xlxs\",\n","]\n","\n","if ON_COLAB:\n","    # Colab manual upload often lands in /content\n","    PROMPTS_CANDIDATES.extend([\n","        \"/content/prompts.xlsx\",\n","        \"/content/prompts.xlxs\",\n","        \"/content/Prompts.xlsx\",\n","        \"/content/Prompts.xlxs\",\n","    ])\n","\n","if ON_KAGGLE:\n","    # Fixed Kaggle dataset path used in your workflow\n","    PROMPTS_CANDIDATES.append(\"/kaggle/input/datasets/sokolenkotimofei/prompts/Prompts.xlsx\")\n","\n","    # Additional Kaggle dataset input path patterns (fallback)\n","    for pattern in [\n","        \"/kaggle/input/*/*/prompts/prompts.xlsx\",\n","        \"/kaggle/input/*/*/prompts/prompts.xlxs\",\n","        \"/kaggle/input/*/*/prompts/Prompts.xlsx\",\n","        \"/kaggle/input/*/*/prompts/Prompts.xlxs\",\n","        \"/kaggle/input/*/prompts/prompts.xlsx\",\n","        \"/kaggle/input/*/prompts/prompts.xlxs\",\n","        \"/kaggle/input/*/prompts/Prompts.xlsx\",\n","        \"/kaggle/input/*/prompts/Prompts.xlxs\",\n","    ]:\n","        PROMPTS_CANDIDATES.extend(sorted(glob.glob(pattern)))\n","\n","# Keep order, remove duplicates\n","PROMPTS_CANDIDATES = list(dict.fromkeys(PROMPTS_CANDIDATES))\n","\n","API_READY_TIMEOUT = int(os.environ.get(\"FORGE_API_READY_TIMEOUT\", \"180\"))\n","API_READY_INTERVAL = float(os.environ.get(\"FORGE_API_READY_INTERVAL\", \"3\"))\n","FORGE_BG_LOG = os.path.join(VOLUME_DIR, \"forge_background.log\")\n","\n","\n","def diagnose_api_unreachable(base_url: str):\n","    print(\"\\n[DIAG] Forge API still unavailable.\")\n","    print(\"[DIAG] Expected run order for Kaggle/Colab: 1) SETTINGS → 2) DOWNLOAD BLOCK → 3) OPTIONAL BOOTSTRAP (cell 7) → 4) OPTIONAL START FORGE (cell 8) → 5) API GENERATION (this cell).\")\n","\n","    launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n","    if not os.path.exists(launch_script):\n","        print(f\"[DIAG] webui.sh not found: {launch_script}\")\n","        print(\"[DIAG] Run OPTIONAL BOOTSTRAP cell first (cell 7).\")\n","\n","    if os.path.exists(FORGE_BG_LOG):\n","        print(f\"[DIAG] Found Forge background log: {FORGE_BG_LOG}\")\n","        try:\n","            with open(FORGE_BG_LOG, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","                tail_lines = f.readlines()[-20:]\n","            print(\"[DIAG] Last Forge log lines:\")\n","            print(\"\".join(tail_lines).strip() or \"[DIAG] (log is empty)\")\n","        except Exception as log_err:\n","            print(f\"[DIAG] Failed to read Forge log: {log_err}\")\n","    else:\n","        print(f\"[DIAG] Forge log not found: {FORGE_BG_LOG}\")\n","        print(\"[DIAG] Start OPTIONAL START FORGE IN BACKGROUND cell (cell 8), then retry this cell.\")\n","\n","def wait_for_api_ready(base_url: str, timeout_s: int = API_READY_TIMEOUT, interval_s: float = API_READY_INTERVAL):\n","    start = time.time()\n","    last_error = None\n","    while (time.time() - start) < timeout_s:\n","        try:\n","            r = requests.get(f\"{base_url}/sdapi/v1/progress\", timeout=10)\n","            if r.status_code < 500:\n","                return True\n","            last_error = f\"HTTP {r.status_code}\"\n","        except Exception as e:\n","            last_error = str(e)\n","        time.sleep(interval_s)\n","    diagnose_api_unreachable(base_url)\n","    raise RuntimeError(\n","        f\"Forge API is not reachable at {base_url} after {timeout_s}s. \"\n","        f\"Last error: {last_error}. \"\n","        \"Run cells 7 and 8 first on Kaggle/Colab, then rerun this API cell.\"\n","    )\n","\n","\n","LOG_PATH = os.path.join(VOLUME_DIR, \"log.txt\")\n","API_IMAGES_DIR = os.path.join(OUTPUTS_DIR, \"api_generated\")\n","os.makedirs(API_IMAGES_DIR, exist_ok=True)\n","\n","\n","CONFLICT_RULES = [\n","    ((\"hr_resize_x\", \"hr_resize_y\"), (\"hr_scale\",)),\n","]\n","\n","\n","def log_line(text: str):\n","    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","    line = f\"[{ts}] {text}\"\n","    print(line)\n","    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n","        f.write(line + \"\\n\")\n","\n","\n","def normalize_value(value):\n","    if isinstance(value, str):\n","        stripped = value.strip()\n","        lowered = stripped.lower()\n","        if lowered in {\"\", \"null\", \"none\", \"nan\"}:\n","            return None\n","        if lowered in {\"true\", \"yes\", \"1\"}:\n","            return True\n","        if lowered in {\"false\", \"no\", \"0\"}:\n","            return False\n","        if re.fullmatch(r\"-?\\d+\", stripped):\n","            return int(stripped)\n","        if re.fullmatch(r\"-?\\d+\\.\\d+\", stripped):\n","            return float(stripped)\n","        return stripped\n","    return value\n","\n","\n","def first_existing_path(candidates):\n","    for p in candidates:\n","        if os.path.exists(p):\n","            return p\n","    return None\n","\n","\n","def parse_workbook(path):\n","    wb = load_workbook(path, data_only=True)\n","    ws = wb.active\n","\n","    instruction_parts = [str(v).strip() for v in ws[1] if v is not None and str(v).strip()]\n","    if not instruction_parts:\n","        raise ValueError(\"Первая строка (инструкция) пустая\")\n","    instruction = \" \".join(instruction_parts)\n","\n","    headers = [str(v).strip() if v is not None else \"\" for v in ws[2]]\n","    if not any(headers):\n","        raise ValueError(\"Вторая строка должна содержать имена переменных (заголовки столбцов)\")\n","\n","    rows = []\n","    for row_idx in range(3, ws.max_row + 1):\n","        row_values = [normalize_value(v) for v in next(ws.iter_rows(min_row=row_idx, max_row=row_idx, values_only=True))]\n","        if all(v is None for v in row_values):\n","            continue\n","\n","        row_map = {}\n","        for idx, key in enumerate(headers):\n","            if not key:\n","                continue\n","            value = row_values[idx] if idx < len(row_values) else None\n","            if value is None:\n","                continue\n","            row_map[key] = value\n","        rows.append(row_map)\n","\n","    if not rows:\n","        raise ValueError(\"Не найдено строк данных (начиная с 3-й строки)\")\n","\n","    return instruction, rows\n","\n","\n","def render_instruction(template: str, variables: dict):\n","    def repl(match):\n","        key = match.group(1)\n","        return str(variables.get(key, match.group(0)))\n","    return re.sub(r\"\\{([a-zA-Z0-9_]+)\\}\", repl, template)\n","\n","\n","def apply_conflict_rules(payload: dict):\n","    cleaned = dict(payload)\n","    for primary_keys, conflicting_keys in CONFLICT_RULES:\n","        primary_present = all((k in cleaned and cleaned[k] is not None) for k in primary_keys)\n","        if primary_present:\n","            for ck in conflicting_keys:\n","                cleaned.pop(ck, None)\n","    return cleaned\n","\n","\n","def fetch_txt2img_params_dump():\n","    try:\n","        response = requests.get(OPENAPI_URL, timeout=30)\n","        response.raise_for_status()\n","        spec = response.json()\n","        schemas = spec.get(\"components\", {}).get(\"schemas\", {})\n","        candidates = [\n","            \"StableDiffusionTxt2ImgProcessingApi\",\n","            \"Txt2ImgRequest\",\n","            \"StableDiffusionProcessingTxt2Img\",\n","        ]\n","        for name in candidates:\n","            if name in schemas:\n","                props = schemas[name].get(\"properties\", {})\n","                return json.dumps({k: v.get(\"type\", \"unknown\") for k, v in props.items()}, ensure_ascii=False, indent=2)\n","        return json.dumps(spec.get(\"paths\", {}).get(\"/sdapi/v1/txt2img\", {}), ensure_ascii=False, indent=2)\n","    except Exception as e:\n","        return f\"Не удалось получить список переменных: {e}\"\n","\n","\n","def save_images_from_response(images_b64, generation_idx):\n","    saved = 0\n","    for i, b64 in enumerate(images_b64, start=1):\n","        image_data = b64.split(\",\", 1)[-1]\n","        file_name = f\"gen_{generation_idx:04d}_{i:02d}.png\"\n","        file_path = os.path.join(API_IMAGES_DIR, file_name)\n","        with open(file_path, \"wb\") as f:\n","            f.write(base64.b64decode(image_data))\n","        saved += 1\n","    return saved\n","\n","\n","def archive_outputs(tag: str):\n","    stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    archive_name = os.path.join(VOLUME_DIR, f\"outputs_{tag}_{stamp}.zip\")\n","    with zipfile.ZipFile(archive_name, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n","        for root, _, files in os.walk(OUTPUTS_DIR):\n","            for file in files:\n","                full_path = os.path.join(root, file)\n","                rel_path = os.path.relpath(full_path, OUTPUTS_DIR)\n","                zf.write(full_path, rel_path)\n","\n","    for entry in os.listdir(OUTPUTS_DIR):\n","        p = os.path.join(OUTPUTS_DIR, entry)\n","        if os.path.isdir(p):\n","            shutil.rmtree(p)\n","        else:\n","            os.remove(p)\n","    os.makedirs(API_IMAGES_DIR, exist_ok=True)\n","    log_line(f\"ARCHIVE created: {archive_name}. OUTPUTS_DIR cleaned.\")\n","\n","\n","wait_for_api_ready(API_BASE)\n","\n","prompts_path = first_existing_path(PROMPTS_CANDIDATES)\n","if not prompts_path:\n","    raise FileNotFoundError(\n","        \"Файл prompts.xlsx/prompts.xlxs не найден. Ожидались пути: \" + \", \".join(PROMPTS_CANDIDATES)\n","    )\n","\n","instruction_template, generation_rows = parse_workbook(prompts_path)\n","log_line(f\"Loaded prompts file: {prompts_path}. Rows for generation: {len(generation_rows)}\")\n","\n","syntax_error_dumped = False\n","images_since_archive = 0\n","\n","for generation_idx, row_values in enumerate(generation_rows, start=1):\n","    payload = dict(row_values)\n","\n","    if \"prompt\" not in payload:\n","        payload[\"prompt\"] = render_instruction(instruction_template, row_values)\n","\n","    payload = {k: v for k, v in payload.items() if v is not None}\n","    payload = apply_conflict_rules(payload)\n","\n","    try:\n","        response = requests.post(TXT2IMG_URL, json=payload, timeout=1800)\n","        if response.status_code >= 400:\n","            err_text = response.text[:1200]\n","            if not syntax_error_dumped:\n","                params_dump = fetch_txt2img_params_dump()\n","                log_line(f\"#{generation_idx} FAIL syntax/validation: {response.status_code} {err_text}\")\n","                log_line(\"AVAILABLE PARAMS DUMP START\")\n","                with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n","                    f.write(params_dump + \"\\n\")\n","                log_line(\"AVAILABLE PARAMS DUMP END\")\n","                syntax_error_dumped = True\n","            else:\n","                log_line(f\"#{generation_idx} FAIL: {response.status_code} {err_text}\")\n","            continue\n","\n","        result = response.json()\n","        images = result.get(\"images\", []) or []\n","        saved_now = save_images_from_response(images, generation_idx)\n","        images_since_archive += saved_now\n","        log_line(f\"#{generation_idx} OK images={saved_now}\")\n","\n","        if images_since_archive >= 15:\n","            archive_outputs(tag=f\"part_{generation_idx:04d}\")\n","            images_since_archive = 0\n","\n","    except requests.exceptions.Timeout:\n","        log_line(f\"#{generation_idx} FAIL: timeout (possible heavy generation or API freeze)\")\n","    except requests.exceptions.RequestException as e:\n","        reason = str(e)\n","        if \"out of memory\" in reason.lower() or \"oom\" in reason.lower():\n","            reason = \"OOM\"\n","        log_line(f\"#{generation_idx} FAIL: {reason}\")\n","    except Exception as e:\n","        log_line(f\"#{generation_idx} FAIL: unexpected error: {e}\")\n","\n","if images_since_archive > 0:\n","    archive_outputs(tag=\"final\")\n","\n","log_line(\"Generation cycle completed\")\n","\n"],"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":914},"id":"OWUeeY4xG4SI","executionInfo":{"status":"error","timestamp":1771324494390,"user_tz":-120,"elapsed":182913,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"36f646dd-fb4f-4357-f8df-bbf6f6d7d46d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[DIAG] Forge API still unavailable.\n","[DIAG] Expected run order for Kaggle/Colab: 1) SETTINGS → 2) DOWNLOAD BLOCK → 3) OPTIONAL BOOTSTRAP (cell 7) → 4) OPTIONAL START FORGE (cell 8) → 5) API GENERATION (this cell).\n","[DIAG] Found Forge background log: /content/volume/forge_background.log\n","[DIAG] Last Forge log lines:\n","return command.main(cmd_args)\n","  File \"/content/stable-diffusion-webui-forge/venv/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 158, in main\n","    with self.main_context():\n","  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n","    next(self.gen)\n","  File \"/content/stable-diffusion-webui-forge/venv/lib/python3.10/site-packages/pip/_internal/cli/command_context.py\", line 20, in main_context\n","    with self._main_context:\n","  File \"/usr/lib/python3.10/contextlib.py\", line 561, in __exit__\n","    if cb(*exc_details):\n","  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n","    next(self.gen)\n","  File \"/content/stable-diffusion-webui-forge/venv/lib/python3.10/site-packages/pip/_internal/operations/build/build_tracker.py\", line 51, in get_build_tracker\n","    with BuildTracker(root) as tracker:\n","  File \"/content/stable-diffusion-webui-forge/venv/lib/python3.10/site-packages/pip/_internal/operations/build/build_tracker.py\", line 83, in __exit__\n","    self.cleanup()\n","  File \"/content/stable-diffusion-webui-forge/venv/lib/python3.10/site-packages/pip/_internal/operations/build/build_tracker.py\", line 129, in cleanup\n","    logger.debug(\"Removed build tracker: %r\", self._root)\n","Message: 'Removed build tracker: %r'\n","Arguments: ('/tmp/pip-build-tracker-84ct33if',)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Forge API is not reachable at http://127.0.0.1:17860 after 180s. Last error: HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88ef3f50>: Failed to establish a new connection: [Errno 111] Connection refused')). Run cells 7 and 8 first on Kaggle/Colab, then rerun this API cell.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1637965176.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m \u001b[0mwait_for_api_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_BASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0mprompts_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_existing_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROMPTS_CANDIDATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1637965176.py\u001b[0m in \u001b[0;36mwait_for_api_ready\u001b[0;34m(base_url, timeout_s, interval_s)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdiagnose_api_unreachable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;34mf\"Forge API is not reachable at {base_url} after {timeout_s}s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;34mf\"Last error: {last_error}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Forge API is not reachable at http://127.0.0.1:17860 after 180s. Last error: HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88ef3f50>: Failed to establish a new connection: [Errno 111] Connection refused')). Run cells 7 and 8 first on Kaggle/Colab, then rerun this API cell."]}],"execution_count":8},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wM3J4QA4G4SK","executionInfo":{"status":"ok","timestamp":1771323591906,"user_tz":-120,"elapsed":20593,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"2d27be75-dc29-4580-c539-1411f00ca22f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking/installing platform dependencies...\n","FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\n","Cloning WebUI Forge...\n","Optional bootstrap finished.\n"]}],"source":["### OPTIONAL: KAGGLE/COLAB FORGE BOOTSTRAP ###\n","\n","import os\n","import shutil\n","import subprocess\n","\n","if not (ON_KAGGLE or ON_COLAB):\n","    print(\"Optional cell: предназначена только для Kaggle/Colab. Текущая платформа пропущена.\")\n","else:\n","    required_packages = [\"git\", \"python3-venv\", \"python3-pip\"]\n","    print(\"Checking/installing platform dependencies...\")\n","    subprocess.run([\"apt\", \"update\", \"-qq\"], check=False)\n","    subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", *required_packages], check=False)\n","\n","    launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n","    git_head = os.path.join(FORGE_DIR, \".git\", \"HEAD\")\n","    forge_ready = os.path.isfile(launch_script) and os.path.isfile(git_head)\n","\n","    if forge_ready:\n","        print(\"WebUI Forge already exists and looks valid, skipping clone.\")\n","    else:\n","        if os.path.isdir(FORGE_DIR):\n","            print(\"FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\")\n","            shutil.rmtree(FORGE_DIR)\n","\n","        print(\"Cloning WebUI Forge...\")\n","        subprocess.run([\n","            \"git\", \"clone\", \"https://github.com/lllyasviel/stable-diffusion-webui-forge\", FORGE_DIR\n","        ], check=True)\n","\n","        if not os.path.isfile(os.path.join(FORGE_DIR, \"webui.sh\")):\n","            raise FileNotFoundError(\"Clone completed but webui.sh not found. Check repository state.\")\n","\n","    print(\"Optional bootstrap finished.\")\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ri-Vg3ByG4SK","executionInfo":{"status":"ok","timestamp":1771323671317,"user_tz":-120,"elapsed":170,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"567c7b90-ed82-4b15-aa85-0d2b3e97955a"},"outputs":[{"output_type":"stream","name":"stdout","text":["WebUI Forge started in background mode as user 'forge'\n","Log file: /content/volume/forge_background.log\n","Tip: use !tail -f /content/volume/forge_background.log\n"]}],"source":["### OPTIONAL: START WEBUI FORGE IN BACKGROUND ###\n","\n","import os\n","import subprocess\n","\n","FORGE_ARGS = \"--xformers --api --cuda-malloc --cuda-stream --pin-shared-memory --theme dark --port 17860\"\n","\n","if not os.path.isdir(FORGE_DIR):\n","    raise FileNotFoundError(f\"Forge directory not found: {FORGE_DIR}\")\n","\n","launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n","if not os.path.exists(launch_script):\n","    raise FileNotFoundError(f\"Launch script not found: {launch_script}\")\n","\n","log_file = os.path.join(VOLUME_DIR, \"forge_background.log\")\n","cmd = f\"cd {FORGE_DIR} && nohup bash webui.sh {FORGE_ARGS} > {log_file} 2>&1 &\"\n","\n","if ON_COLAB and os.geteuid() == 0:\n","    run_user = os.environ.get(\"FORGE_RUN_USER\", \"forge\")\n","\n","    user_exists = subprocess.run([\"id\", \"-u\", run_user], capture_output=True, text=True).returncode == 0\n","    if not user_exists:\n","        subprocess.run([\"useradd\", \"-m\", \"-s\", \"/bin/bash\", run_user], check=True)\n","\n","    subprocess.run([\"chown\", \"-R\", f\"{run_user}:{run_user}\", FORGE_DIR], check=True)\n","    subprocess.run([\"chown\", \"-R\", f\"{run_user}:{run_user}\", VOLUME_DIR], check=True)\n","\n","    subprocess.run([\"su\", \"-s\", \"/bin/bash\", \"-c\", cmd, run_user], check=True)\n","    print(f\"WebUI Forge started in background mode as user '{run_user}'\")\n","else:\n","    subprocess.run([\"bash\", \"-lc\", cmd], check=True)\n","    print(\"WebUI Forge started in background mode\")\n","\n","print(f\"Log file: {log_file}\")\n","print(\"Tip: use !tail -f\", log_file)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":440},"id":"a5aqcUoSG4SL","executionInfo":{"status":"error","timestamp":1771323920971,"user_tz":-120,"elapsed":231675,"user":{"displayName":"Sokolenko Timofei","userId":"14202647928619858996"}},"outputId":"cda71756-3274-46c7-e645-67ceb4dda88f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Проверка связи с Forge API: http://127.0.0.1:17860/sdapi/v1/progress\n","Интервал проверки: 30 сек, таймаут: 1800 сек\n","[   0 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c8951a240>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[  30 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e58c50>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[  60 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e596d0>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[  90 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e59190>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[ 120 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e5a2a0>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[ 150 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e5aa80>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[ 180 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c8950c1d0>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n","[ 210 сек] API ещё не готов (HTTPConnectionPool(host='127.0.0.1', port=17860): Max retries exceeded with url: /sdapi/v1/progress (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6c88e5a360>: Failed to establish a new connection: [Errno 111] Connection refused'))). Следующая проверка через 30 сек...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-790481253.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{elapsed:>4} сек] API ещё не готов ({last_error}). Следующая проверка через {WAIT_INTERVAL} сек...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWAIT_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     raise RuntimeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["### OPTIONAL: WAIT FOR FORGE API CONNECTION ###\n","\n","import time\n","import requests\n","\n","API_BASE = os.environ.get(\"FORGE_API_BASE\", \"http://127.0.0.1:17860\")\n","PING_URL = f\"{API_BASE}/sdapi/v1/progress\"\n","WAIT_TIMEOUT = int(os.environ.get(\"FORGE_WAIT_TIMEOUT\", \"1800\"))\n","WAIT_INTERVAL = int(os.environ.get(\"FORGE_WAIT_INTERVAL\", \"30\"))\n","\n","print(f\"Проверка связи с Forge API: {PING_URL}\")\n","print(f\"Интервал проверки: {WAIT_INTERVAL} сек, таймаут: {WAIT_TIMEOUT} сек\")\n","\n","start = time.time()\n","attempt = 0\n","last_error = None\n","\n","while (time.time() - start) < WAIT_TIMEOUT:\n","    attempt += 1\n","    try:\n","        r = requests.get(PING_URL, timeout=10)\n","        if r.status_code < 500:\n","            elapsed = int(time.time() - start)\n","            print(f\"✅ связь установлена: Forge API готов (попытка {attempt}, ~{elapsed} сек).\")\n","            break\n","        last_error = f\"HTTP {r.status_code}\"\n","    except Exception as e:\n","        last_error = str(e)\n","\n","    elapsed = int(time.time() - start)\n","    print(f\"[{elapsed:>4} сек] API ещё не готов ({last_error}). Следующая проверка через {WAIT_INTERVAL} сек...\")\n","    time.sleep(WAIT_INTERVAL)\n","else:\n","    raise RuntimeError(\n","        f\"Не удалось дождаться Forge API за {WAIT_TIMEOUT} сек. Последняя ошибка: {last_error}\"\n","    )\n"]}]}