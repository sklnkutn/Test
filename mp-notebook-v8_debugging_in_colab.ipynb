{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "14sXDYyegbMQjRaEottMtnEr-SDILHZrW",
     "timestamp": 1771328894458
    }
   ],
   "gpuType": "T4"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"color:rgb(0,0,255);font-size: 40px;font-weight:700;\">\n",
    "MAIN SETTINGS\n",
    "</div>"
   ],
   "metadata": {
    "id": "8u27b0sPG4SA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "###SETTINGS###\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import subprocess\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from getpass import getpass\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Platform detection\n",
    "ON_KAGGLE = os.path.exists('/kaggle')\n",
    "ON_COLAB = 'COLAB_RELEASE_TAG' in os.environ or os.path.exists('/content')\n",
    "ON_VAST = any(k in os.environ for k in (\"VAST_CONTAINERLABEL\", \"VAST_TCP_PORT_22\", \"CONTAINER_ID\")) or os.path.exists('/workspace')\n",
    "\n",
    "\n",
    "MAX_PARALLEL_DOWNLOADS = max(1, int(os.environ.get(\"MAX_PARALLEL_DOWNLOADS\", \"3\")))\n",
    "MIN_VALID_FILE_BYTES = int(os.environ.get(\"MIN_VALID_FILE_BYTES\", \"1000000\"))\n",
    "\n",
    "if shutil.which(\"aria2c\") is None:\n",
    "    print(\"aria2c not found → installing...\")\n",
    "    try:\n",
    "        subprocess.run([\"apt\", \"update\", \"-qq\"], check=True, capture_output=True)\n",
    "        result = subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", \"aria2\"], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"aria2c installed successfully\")\n",
    "        else:\n",
    "            print(\"Install failed (code {}):\".format(result.returncode))\n",
    "            print(\"stderr:\", result.stderr.strip())\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"apt error (code {e.returncode}): {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "else:\n",
    "    print(\"aria2c already available\")\n",
    "\n",
    "# Determining the working directory\n",
    "possible_bases = [\n",
    "    \"/workspace\",       # Vast.ai / RunPod\n",
    "    \"/kaggle/working\",  # Kaggle\n",
    "    \"/content\",         # Google Colab\n",
    "]\n",
    "\n",
    "BASE_DIR = None\n",
    "for path in possible_bases:\n",
    "    if os.path.isdir(path):\n",
    "        BASE_DIR = path\n",
    "        break\n",
    "\n",
    "if BASE_DIR is None:\n",
    "    BASE_DIR = os.getcwd()\n",
    "    print(\"WARNING: Known directory not found:\", BASE_DIR)\n",
    "\n",
    "print(\"Working directory:\", BASE_DIR)\n",
    "\n",
    "# Configuration\n",
    "FORGE_DIR        = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\")\n",
    "MODELS_DIR       = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Stable-diffusion\")\n",
    "LORA_DIR         = os.path.join(BASE_DIR, \"stable-diffusion-webui-forge\", \"models\", \"Lora\")\n",
    "CONTROLNET_DIR   = os.path.join(FORGE_DIR, \"extensions\", \"sd-webui-controlnet\")\n",
    "CONTROLNET_MODELS_DIR = os.path.join(CONTROLNET_DIR, \"models\")\n",
    "EXTENSIONS_DIR   = os.path.join(FORGE_DIR, \"extensions\")\n",
    "OUTPUTS_DIR      = os.path.join(FORGE_DIR, \"outputs\")\n",
    "VOLUME_DIR       = os.path.join(BASE_DIR, \"volume\")\n",
    "GEN_DIR          = os.path.join(BASE_DIR, \"gen\")\n",
    "\n",
    "for d in [MODELS_DIR, LORA_DIR, CONTROLNET_DIR, CONTROLNET_MODELS_DIR, EXTENSIONS_DIR, OUTPUTS_DIR, VOLUME_DIR, GEN_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dependencies used by generation cell\n",
    "for pkg in [\"openpyxl\", \"requests\"]:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except Exception:\n",
    "        print(f\"Installing missing dependency: {pkg}\")\n",
    "        subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"-q\", pkg], check=False)\n",
    "\n",
    "\n",
    "def get_secret(name: str):\n",
    "    \"\"\"Get secret from env/Kaggle/Colab only.\"\"\"\n",
    "    value = os.environ.get(name)\n",
    "    if value:\n",
    "        return value.strip(), \"env\"\n",
    "\n",
    "    # Kaggle secrets\n",
    "    if ON_KAGGLE:\n",
    "        try:\n",
    "            from kaggle_secrets import UserSecretsClient\n",
    "            value = UserSecretsClient().get_secret(name)\n",
    "            if value:\n",
    "                return value.strip(), \"kaggle_secrets\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Colab secrets panel: from google.colab import userdata\n",
    "    if ON_COLAB:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            value = userdata.get(name)\n",
    "            if value:\n",
    "                return value.strip(), \"colab_userdata\"\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "CIVITAI_TOKEN, CIVITAI_SRC = get_secret(\"CIVITAI_TOKEN\")\n",
    "HF_TOKEN, HF_SRC = get_secret(\"HF_TOKEN\")\n",
    "\n",
    "if not CIVITAI_TOKEN:\n",
    "    manual_civitai = getpass(\"Enter CIVITAI_TOKEN (leave blank to skip): \").strip()\n",
    "    if manual_civitai:\n",
    "        CIVITAI_TOKEN, CIVITAI_SRC = manual_civitai, \"manual_input\"\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    manual_hf = getpass(\"Enter HF_TOKEN (leave blank to skip): \").strip()\n",
    "    if manual_hf:\n",
    "        HF_TOKEN, HF_SRC = manual_hf, \"manual_input\"\n",
    "\n",
    "TOKENS = {}\n",
    "if CIVITAI_TOKEN:\n",
    "    TOKENS[\"CIVITAI\"] = CIVITAI_TOKEN\n",
    "if HF_TOKEN:\n",
    "    TOKENS[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "print(\"Token sources:\")\n",
    "print(f\"  CIVITAI_TOKEN: {CIVITAI_SRC or 'not found'}\")\n",
    "print(f\"  HF_TOKEN: {HF_SRC or 'not found'}\")\n",
    "if ON_VAST:\n",
    "    print(\"Vast.ai tip: add CIVITAI_TOKEN/HF_TOKEN in template env vars, restart container, then rerun this cell.\")\n",
    "\n",
    "if not CIVITAI_TOKEN:\n",
    "    print(\"CivitAI token not found\")\n",
    "if not HF_TOKEN:\n",
    "    print(\"HF token not found\")\n",
    "if not TOKENS:\n",
    "    raise RuntimeError(\"No tokens were provided. Set secrets or enter at least one token (CivitAI or HF).\")\n",
    "\n",
    "\n",
    "def _prepare_download_url(url, token):\n",
    "    \"\"\"CivitAI download works more reliably with token as query param.\"\"\"\n",
    "    if token and \"civitai.com/api/download/models\" in url and \"token=\" not in url:\n",
    "        sep = \"&\" if \"?\" in url else \"?\"\n",
    "        return f\"{url}{sep}{urlencode({'token': token})}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "def _looks_valid_file(path, min_bytes=MIN_VALID_FILE_BYTES):\n",
    "    return os.path.exists(path) and os.path.getsize(path) > min_bytes\n",
    "\n",
    "\n",
    "def _human_mb(num_bytes):\n",
    "    return f\"{num_bytes / (1024 * 1024):.1f} MB\"\n",
    "\n",
    "\n",
    "def _estimate_expected_mb(label):\n",
    "    # Examples: \"151 MB\", \"6,46 GB\"\n",
    "    match = re.search(r\"(\\d+[\\.,]?\\d*)\\s*(MB|GB)\", label, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None\n",
    "    value = float(match.group(1).replace(',', '.'))\n",
    "    unit = match.group(2).upper()\n",
    "    return value * (1024 if unit == \"GB\" else 1)\n",
    "\n",
    "\n",
    "def _size_sanity_warning(path, expected_mb, tolerance=0.7):\n",
    "    if expected_mb is None or not os.path.exists(path):\n",
    "        return\n",
    "    actual_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "    if actual_mb < expected_mb * tolerance:\n",
    "        print(f\"  WARNING: file size looks low ({actual_mb:.1f} MB vs expected ~{expected_mb:.1f} MB)\")\n",
    "\n",
    "\n",
    "def _has_min_free_disk(path, required_mb, reserve_mb=1024):\n",
    "    if required_mb is None:\n",
    "        return True\n",
    "    usage = shutil.disk_usage(path)\n",
    "    free_mb = usage.free / (1024 * 1024)\n",
    "    return free_mb >= (required_mb + reserve_mb)\n",
    "\n",
    "\n",
    "def _download_one(job, target_dir):\n",
    "    label, url, filename, token_name = job\n",
    "    token = TOKENS.get(token_name)\n",
    "    output_path = os.path.join(target_dir, filename)\n",
    "\n",
    "    expected_mb = _estimate_expected_mb(label)\n",
    "\n",
    "    if _looks_valid_file(output_path):\n",
    "        size = os.path.getsize(output_path)\n",
    "        print(f\"[SKIP] {label}: already exists ({_human_mb(size)})\")\n",
    "        _size_sanity_warning(output_path, expected_mb)\n",
    "        return (label, True, \"exists\")\n",
    "\n",
    "    if expected_mb is not None and not _has_min_free_disk(target_dir, expected_mb):\n",
    "        return (label, False, \"insufficient_disk\")\n",
    "\n",
    "    tmp_path = output_path + \".part\"\n",
    "    if os.path.exists(tmp_path):\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "    final_url = _prepare_download_url(url, token if token_name == \"CIVITAI\" else None)\n",
    "\n",
    "    cmd = [\n",
    "        \"aria2c\",\n",
    "        \"--allow-overwrite=true\",\n",
    "        \"--auto-file-renaming=false\",\n",
    "        \"--continue=true\",\n",
    "        \"--max-connection-per-server=16\",\n",
    "        \"--split=16\",\n",
    "        \"--min-split-size=1M\",\n",
    "        \"--console-log-level=warn\",\n",
    "        \"--summary-interval=1\",\n",
    "        \"--check-certificate=false\",\n",
    "        \"--out\", os.path.basename(tmp_path),\n",
    "        \"--dir\", target_dir,\n",
    "        final_url,\n",
    "    ]\n",
    "\n",
    "    if token_name == \"HF_TOKEN\" and token:\n",
    "        cmd.insert(-1, f\"--header=Authorization: Bearer {token}\")\n",
    "\n",
    "    print(f\"[DOWNLOADING] {label}\")\n",
    "    result = subprocess.run(cmd, text=True, capture_output=True)\n",
    "    if result.returncode != 0:\n",
    "        stderr = (result.stderr or \"\").strip()\n",
    "        stdout = (result.stdout or \"\").strip()\n",
    "        msg = stderr or stdout or f\"aria2c exited {result.returncode}\"\n",
    "        if os.path.exists(tmp_path):\n",
    "            os.remove(tmp_path)\n",
    "        return (label, False, msg)\n",
    "\n",
    "    if not _looks_valid_file(tmp_path):\n",
    "        size = os.path.getsize(tmp_path) if os.path.exists(tmp_path) else 0\n",
    "        if os.path.exists(tmp_path):\n",
    "            os.remove(tmp_path)\n",
    "        return (label, False, f\"downloaded file too small ({_human_mb(size)})\")\n",
    "\n",
    "    os.replace(tmp_path, output_path)\n",
    "    _size_sanity_warning(output_path, expected_mb)\n",
    "    return (label, True, _human_mb(os.path.getsize(output_path)))\n",
    "\n",
    "\n",
    "def run_download_list(download_list, target_dir, title):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    if not download_list:\n",
    "        print(\"No items.\")\n",
    "        return\n",
    "\n",
    "    workers = min(MAX_PARALLEL_DOWNLOADS, len(download_list))\n",
    "    print(f\"Parallel downloads: {workers}\")\n",
    "\n",
    "    ok = 0\n",
    "    fail = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "        futures = [ex.submit(_download_one, job, target_dir) for job in download_list]\n",
    "        for fut in as_completed(futures):\n",
    "            label, success, info = fut.result()\n",
    "            if success:\n",
    "                ok += 1\n",
    "                print(f\"[OK]   {label} -> {info}\")\n",
    "            else:\n",
    "                fail += 1\n",
    "                print(f\"[FAIL] {label} -> {info}\")\n",
    "\n",
    "    print(f\"Done: OK={ok}, FAIL={fail}\")\n",
    "    if fail > 0:\n",
    "        raise RuntimeError(f\"Some downloads failed in {title}: {fail} item(s)\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTzG8SwHG4SC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771328411100,
     "user_tz": -120,
     "elapsed": 18125,
     "user": {
      "displayName": "Sokolenko Timofei",
      "userId": "14202647928619858996"
     }
    },
    "outputId": "f393f94c-ad89-4ada-cf09-46ff7662971f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aria2c not found → installing...\n",
      "aria2c installed successfully\n",
      "Working directory: /content\n",
      "Token sources:\n",
      "  CIVITAI_TOKEN: colab_userdata\n",
      "  HF_TOKEN: colab_userdata\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wM3J4QA4G4SK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771328433337,
     "user_tz": -120,
     "elapsed": 22233,
     "user": {
      "displayName": "Sokolenko Timofei",
      "userId": "14202647928619858996"
     }
    },
    "outputId": "6be9f00e-054b-4d09-a4c0-9c4486b602bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking/installing platform dependencies...\n",
      "FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\n",
      "Cloning WebUI Forge...\n",
      "Optional bootstrap finished.\n"
     ]
    }
   ],
   "source": [
    "### OPTIONAL: KAGGLE/COLAB FORGE BOOTSTRAP ###\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "if not (ON_KAGGLE or ON_COLAB):\n",
    "    print(\"Optional cell: предназначена только для Kaggle/Colab. Текущая платформа пропущена.\")\n",
    "else:\n",
    "    required_packages = [\"git\", \"python3-venv\", \"python3-pip\"]\n",
    "    print(\"Checking/installing platform dependencies...\")\n",
    "    subprocess.run([\"apt\", \"update\", \"-qq\"], check=False)\n",
    "    subprocess.run([\"apt\", \"install\", \"-y\", \"-qq\", *required_packages], check=False)\n",
    "\n",
    "    launch_script = os.path.join(FORGE_DIR, \"webui.sh\")\n",
    "    git_head = os.path.join(FORGE_DIR, \".git\", \"HEAD\")\n",
    "    forge_ready = os.path.isfile(launch_script) and os.path.isfile(git_head)\n",
    "\n",
    "    if forge_ready:\n",
    "        print(\"WebUI Forge already exists and looks valid, skipping clone.\")\n",
    "    else:\n",
    "        if os.path.isdir(FORGE_DIR):\n",
    "            print(\"FORGE_DIR exists but WebUI Forge is incomplete/corrupted. Recreating...\")\n",
    "            shutil.rmtree(FORGE_DIR)\n",
    "\n",
    "        print(\"Cloning WebUI Forge...\")\n",
    "        subprocess.run([\n",
    "            \"git\", \"clone\", \"https://github.com/lllyasviel/stable-diffusion-webui-forge\", FORGE_DIR\n",
    "        ], check=True)\n",
    "\n",
    "        if not os.path.isfile(os.path.join(FORGE_DIR, \"webui.sh\")):\n",
    "            raise FileNotFoundError(\"Clone completed but webui.sh not found. Check repository state.\")\n",
    "\n",
    "    print(\"Optional bootstrap finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "### RUN WEBUI (PURE PYTHON) ###\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "forge_dir = Path(FORGE_DIR)\n",
    "if not forge_dir.exists():\n",
    "    raise FileNotFoundError(f\"FORGE_DIR не найден: {forge_dir}\")\n",
    "\n",
    "launch_utils_path = forge_dir / \"modules\" / \"launch_utils.py\"\n",
    "if launch_utils_path.exists():\n",
    "    content = launch_utils_path.read_text(encoding=\"utf-8\")\n",
    "    old = 'run_pip(f\"install {clip_package}\", \"clip\")'\n",
    "    new = 'run_pip(f\"install --no-build-isolation --no-use-pep517 {clip_package}\", \"clip\")'\n",
    "    if old in content and new not in content:\n",
    "        launch_utils_path.write_text(content.replace(old, new), encoding=\"utf-8\")\n",
    "        print(\"Patched CLIP install command (no-build-isolation + no-use-pep517).\")\n",
    "    else:\n",
    "        print(\"CLIP install patch already applied or not required.\")\n",
    "else:\n",
    "    print(f\"Warning: {launch_utils_path} not found, skipping CLIP patch.\")\n",
    "\n",
    "cmd = [\"bash\", \"webui.sh\", \"-f\", \"--xformers\", \"--api\", \"--port\", \"17860\"]\n",
    "print(\"Running:\", \" \".join(cmd), \"in\", forge_dir)\n",
    "subprocess.run(cmd, cwd=forge_dir, check=True)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpZBUyZoYFHL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1771328692825,
     "user_tz": -120,
     "elapsed": 188283,
     "user": {
      "displayName": "Sokolenko Timofei",
      "userId": "14202647928619858996"
     }
    },
    "outputId": "9fa9759a-2652-4c2e-d911-73a85dcf233c"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
